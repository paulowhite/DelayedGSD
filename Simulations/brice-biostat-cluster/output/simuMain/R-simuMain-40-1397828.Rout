
R version 4.1.2 (2021-11-01) -- "Bird Hippie"
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ### BATCH_simuMain.R --- 
> #----------------------------------------------------------------------
> ## Author: Paul Blanche
> ## Created: Mar  5 2021 (10:56) 
> ## Version: 
> ## Last-Updated: maj  6 2022 (10:22) 
> ##           By: Brice Ozenne
> ##     Update #: 512
> #----------------------------------------------------------------------
> ## 
> ### Commentary: 
> ## 
> ### Change Log:
> #----------------------------------------------------------------------
> ## 
> ### Code:
> 
> rm(list=ls())
>                                    # {{{ parameters
> ## * parameters
> name <- "ScenarioName" # To save the results
> method <- 1:2 # methods used to compute the boundaries
>                                         #---
> myseed <- 140786598
>                                         #--- to plan the trial ----
> NMC <- 250 # number of sequential simulations to run in parallel. Eg. with 250, then we can run 40 scripts in paralell to get N=10,000 runs in total.
> kMax <- 2  #max number of analyses (including final)
> alpha <- 0.025  #type I error (one sided)
> beta <- 0.2  #type II error
> informationRates <- c(0.5,1)  #planned  information rates
> rho_alpha <- 2  # rho parameter for alpha error spending function
> rho_beta <- 2  # rho parameter for beta error spending function
> ## deltaPower <- 0.75 # just to try another value when Id > Imax
> Id <- 0.55  #(expected) information rate at each decision analysis
> binding <- TRUE
>                                         #
>                                         #---- to generate data -----------
>                                         #
> block <- c(1,1,0,0) 
> allsd <- c(2.5,2.1,2.4) # sd, first from baseline measurement, then the two changes from baseline
> mean0 <- c(10,0,0) # mean placebo group (again, first is absolute value, then change from baseline)
> delta <- c(0,0.6,0.8) # treatment effect
> ar <- (0.86*2)*2 # orginial accrual rate from data from Corine is 0.86 per week, hence we multiply by 2 for by 14 days. As to low, we further multiply by 2
> cor011 <- -0.15 # ~ from data from Corine
> corij1 <- 0.68  # ~ from data from Corine
> cor0j1 <- -0.27  # ~ from data from Corine
> Miss11 <- 5/104 # miss both V1 and V2
> Miss12 <- 1/104 # miss V1 and but not V2
> Miss21 <- 6/104 # do not miss V1 and but miss V2
> Miss22 <- 92/104 # miss none
> PropForInterim <- 0.5 # Decide to have interim analysiz when PropForInterim % of all subjects have had the chance to have one follow-up measuement recorded in the data to be available for analysis.
> theDelta.t <- 1.50001 # time lag to process the data and make them ready to analyze after collecting them (unit is time between two follow-up visits)
> TimeFactor <- 14 ## number of days between two visits
>                                         #
>                                         #--- actually for both planing the trial  and generating data-----
>                                         #
>                                         #
> deltaPower <- abs(delta[3]) # effect (NOT Z-scale/unit, but outcome scale/unit!) that the study is powered for: should we choose ourselves or compute from other numbers above ???
> n <- ceiling(2*2*((allsd[3]/deltaPower)^2)*(qnorm(1-beta)-qnorm(alpha))^2) #104 with Corine's data # should we choose ourselves or compute from the above numbers ???
>                                         # inflate SS as required for interim
> 
> # {{{ Set seeds for parallel computing and reproducibility
> ## * Seed
> iter_sim <- as.numeric(Sys.getenv("SLURM_ARRAY_TASK_ID"))
> n.iter_sim <- as.numeric(Sys.getenv("SLURM_ARRAY_TASK_COUNT"))
> if(is.na(iter_sim)){iter_sim <- 2}
> if(is.na(n.iter_sim)){n.iter_sim <- 10}
> 
> set.seed(140786598)
> allseeds <- sample.int(n = 10*n.iter_sim*NMC, size = n.iter_sim*NMC, replace=FALSE) #x=1:(.Machine$integer.max) seems to be maximal possible
> # }}}
> 
> # {{{ set path to load and save and othe machine specific variables
> ## * path
> path <- "."
> path.res <- file.path(path,"Results","simuMain")
> if(dir.exists(path.res)==FALSE){
+     if(dir.exists(file.path(path,"Results"))==FALSE){
+     dir.create(file.path(path,"Results"))
+     }
+     dir.create(path.res)
+ }
> path.output <- file.path(path,"output","simuMain")
> if(dir.exists(path.output)==FALSE){
+     if(dir.exists(file.path(path,"output"))==FALSE){
+     dir.create(file.path(path,"output"))
+     }
+     dir.create(path.output)
+ }
> # }}}
> 
> 
> ## * libraries and functions
> library(DelayedGSD)
DelayedGSD version 0.0.2
> ## sourceDir <- function(path, trace = TRUE, ...) {
> ##     for (nm in list.files(path, pattern = "[.][RrSsQq]$")) {
> ##         if(trace) cat(nm,":")
> ##         source(file.path(path, nm), ...)
> ##         if(trace) cat("\n")
> ##     }
> ## }
> ## sourceDir(pathToLoad)
>     
> 
> ## * Compute inflation factor and sample size
> plannedB <- vector(mode = "list", length = 3)
> for(iMeth in method){ ## iMeth <- 1
+     plannedB[[iMeth]] <- CalcBoundaries(kMax=kMax,  
+                                         alpha=alpha, 
+                                         beta=beta,  
+                                         InfoR.i=informationRates,  
+                                         InfoR.d=c(Id,1),  
+                                         rho_alpha=rho_alpha,  
+                                         rho_beta=rho_beta,  
+                                         method=iMeth,  
+                                         cNotBelowFixedc=FALSE,
+                                         bindingFutility=binding,
+                                         delta=tail(delta,1))
+     ## summary(plannedB[[1]])
+     ## coef(plannedB[[iMeth]], type = "information")
+ }
Loading required namespace: gsDesign
Loading required package: mvtnorm
Loading required namespace: BB
> inflationFactor <- unlist(lapply(plannedB,function(iP){iP$planned$InflationFactor}))
> nGSD <- ceiling(n*inflationFactor)
> ##  plot(plannedB[[1]])
> 
> #
> # --- just to check---
> ## n
> ## InfoFixed <- ((qnorm(1-beta)-qnorm(alpha))/(deltaPower))^2
> ## InfoFixed
> ## n/(4*(allsd[3])^2)
> #---
> # }}}
> 
> 
> 
> 
> # {{{ technical details to loop
> RES <- NULL # initialize results to save
> allj <- ((iter_sim-1)*NMC + 1):(iter_sim*NMC) # indices of all iterations (replicates) for this job, accountng for the other jobs running in parallel
> # }}}
> 
> ## * Loop
> for(j in allj){ ## j <- 5 ## 5
+     startComp <- Sys.time()
+     myseedi <- allseeds[j]
+     # {{{ TRACE info (e.g. to check the Rout)
+     print(paste0("seed ",myseedi," for ","j=",which(j==allj)," out of ",NMC, " (i.e. j=",j," in [",(iter_sim-1)*NMC + 1,";",iter_sim*NMC,"], as job id is i=",iter_sim,")"))
+     # }}}
+     # {{{ Missing probabilities
+     MyMissProb <- matrix(c(Miss11,Miss12,Miss21,Miss22),ncol=2,nrow=2,byrow=TRUE) # to additionnally remove 1 more because some FASFL=N
+     colnames(MyMissProb) <- c("V2 missing","V2 not missing")
+     rownames(MyMissProb) <- c("V1 missing","V1 not missing")
+     # }}}
+ 
+                                         # {{{ generate data
+     ## ** simulate
+     res <- GenData(n=n, 
+                    N.fw=2,
+                    rand.block=block,
+                    allsd=allsd,
+                    mean0=mean0,
+                    delta=delta,
+                    ar=ar,
+                    cor.01.1=cor011,
+                    cor.ij.1=corij1,
+                    cor.0j.1=cor0j1,
+                    seed=myseedi,
+                    MissProb=MyMissProb,
+                    DigitsOutcome=2,
+                    TimeFactor=TimeFactor,
+                    DigitsTime=0
+                    )
+     d <- res$d
+     ## head(d,n=20)
+                                         # }}}
+                                         # {{{ reformat data like those of Corine
+     ## Make data long format
+     ## dd <- FormatAsCase(d)
+     ## head(dd)
+     ## summary(dd)
+                                         # }}}
+    
+                                         # {{{ make data available at interim
+                                         # Here we stop inclusion data collection for the interim analysis as soon as
+                                         # half of the participants have completed (or had the opportunity to complete) the follow-up 
+     thet <- d$t3[ceiling(n*PropForInterim)]
+     di <- SelectData(d,t=thet)
+     ## ddi <- FormatAsCase(di) # needed ????
+     ## head(d[d$id==52,])
+                                         # }}}
+     ## {{{ analyze data at at interim
+     ## ** interim
+     lmmI <- analyzeData(di, ddf = "nlme", data.decision = sum(d$t1 <= thet + theDelta.t*TimeFactor), getinfo = TRUE, trace = TRUE)
+     ## lmmI <- analyzeData(di, ddf = "nlme", getinfo = TRUE, trace = TRUE)
+ 
+     currentGSD <- vector(mode = "list", length = 3)
+     out.interim <- vector(mode = "list", length = 3)
+     for(iMeth in method){ ## iMeth <- 1
+ 
+         currentGSD[[iMeth]] <- update(plannedB[[iMeth]], delta = lmmI, trace = FALSE)
+ 
+         iConfint.interim <- confint(currentGSD[[iMeth]])
+         iInfo.interim <- coef(currentGSD[[iMeth]], type = "information")
+         iBoundary.interim <- coef(currentGSD[[iMeth]], type = "boundary")
+         iDecision.interim <- coef(currentGSD[[iMeth]], type = "decision")
+ 
+         out.interim[[iMeth]] <-  data.frame(statistic = iConfint.interim[1,"statistic"],
+                                             estimate_ML = iConfint.interim[1,"estimate"],
+                                             se_ML = iConfint.interim[1,"se"],
+                                             info = iInfo.interim[1,"Interim"],
+                                             infoPC = iInfo.interim[1,"Interim.pc"],
+                                             info.pred = iInfo.interim[1,"Decision"],
+                                             infoPC.pred = iInfo.interim[1,"Decision.pc"],
+                                             uk = iBoundary.interim[1,"Ebound"],
+                                             lk = iBoundary.interim[1,"Fbound"],
+                                             decision = iDecision.interim["decision","stage 1"],
+                                             reason = iDecision.interim["reason.interim","stage 1"])
+     }
+     ## currentGSD[[1]]
+     ## plot(currentGSD[[1]])
+ 
+     ## ** decision
+     dDecision <- d[which(d$t1 <= thet + theDelta.t*TimeFactor),]
+     lmmD <- analyzeData(dDecision, ddf = "nlme", getinfo = TRUE, trace = TRUE)
+     
+     out.decision <- vector(mode = "list", length = 3)
+     for(iMeth in method){ ## iMeth <- 1
+           
+         if(out.interim[[iMeth]]$decision == "stop"){
+             currentGSD[[iMeth]] <- update(currentGSD[[iMeth]], delta = lmmD, trace = FALSE)
+             ## plot(currentGSD[[iMeth]])
+ 
+             iConfint.decision <- confint(currentGSD[[iMeth]], method = c("ML","MUE"))
+             iInfo.decision <- coef(currentGSD[[iMeth]], type = "information")
+             iBoundary.decision <- coef(currentGSD[[iMeth]], type = "boundary")
+             iDecision.decision  <- coef(currentGSD[[iMeth]], type = "decision")
+ 
+             out.decision[[iMeth]] <- data.frame(statistic = iConfint.decision[1,"statistic"],
+                                                 p.value_ML = iConfint.decision[iConfint.decision$method == "ML","p.value"],
+                                                 lower_ML = iConfint.decision[iConfint.decision$method == "ML","lower"],
+                                                 upper_ML = iConfint.decision[iConfint.decision$method == "ML","upper"],
+                                                 estimate_ML = iConfint.decision[iConfint.decision$method == "ML","estimate"],
+                                                 p.value_MUE = iConfint.decision[iConfint.decision$method == "MUE","p.value"],
+                                                 lower_MUE = iConfint.decision[iConfint.decision$method == "MUE","lower"],
+                                                 upper_MUE = iConfint.decision[iConfint.decision$method == "MUE","upper"],
+                                                 estimate_MUE = iConfint.decision[iConfint.decision$method == "MUE","estimate"],
+                                                 info = iInfo.decision[1,"Interim"],
+                                                 infoPC = iInfo.decision[1,"Interim.pc"],
+                                                 ck = iBoundary.decision[1,"Cbound"],
+                                                 decision = unname(iDecision.decision["decision","stage 2"])
+                                                 )
+ 
+         }else{
+             ## update information
+             currentGSD[[iMeth]] <- update(currentGSD[[iMeth]], delta = lmmD, k = 1, type.k = "decision", trace = FALSE)
+ 
+             iInfo.decision <- coef(currentGSD[[iMeth]], type = "information")
+             iBoundary.decision <- coef(currentGSD[[iMeth]], type = "boundary")
+ 
+             out.decision[[iMeth]] <- data.frame(statistic = NA,
+                                                 p.value_ML = NA,
+                                                 lower_ML = NA,
+                                                 upper_ML = NA,
+                                                 estimate_ML = NA,
+                                                 p.value_MUE = NA,
+                                                 lower_MUE = NA,
+                                                 upper_MUE = NA,
+                                                 estimate_MUE = NA,
+                                                 info = iInfo.decision[1,"Decision"],
+                                                 infoPC = iInfo.decision[1,"Decision.pc"],
+                                                 ck = iBoundary.decision[1,"Cbound"],
+                                                 decision = NA)
+         }
+     }
+                                         # }}}
+                                         # {{{ Analyze data at decision
+ 
+     ## ** finale
+     dFinal <- d
+     lmmF <- analyzeData(dFinal, ddf = "nlme", getinfo = TRUE, trace = TRUE)
+ 
+     out.final <- vector(mode = "list", length = 3)
+     for(iMeth in method){ ## iMeth <- 1
+         if(out.interim[[iMeth]]$decision == "stop"){
+             out.final[[iMeth]] <- data.frame(statistic = NA,
+                                              p.value_ML = NA,
+                                              lower_ML = NA,
+                                              upper_ML = NA,
+                                              estimate_ML = NA,
+                                              p.value_MUE = NA,
+                                              lower_MUE = NA,
+                                              upper_MUE = NA,
+                                              estimate_MUE = NA,
+                                              info = NA,
+                                              infoPC = NA,
+                                              ck = NA,
+                                              decision = NA)
+ 
+         }else{
+             currentGSD[[iMeth]] <- update(currentGSD[[iMeth]], delta = lmmF, trace = FALSE)
+ 
+             ## plot(test)
+             ## summary(test)
+             iConfint.final <- confint(currentGSD[[iMeth]], method = c("ML","MUE"))
+             iInfo.final <- coef(currentGSD[[iMeth]], type = "information")
+             iBoundary.final <- coef(currentGSD[[iMeth]], type = "boundary")
+             iDecision.final  <- coef(currentGSD[[iMeth]], type = "decision")
+ 
+             out.final[[iMeth]] <- data.frame(statistic = iConfint.final[1,"statistic"],
+                                              p.value_ML = iConfint.final[iConfint.final$method == "ML","p.value"],
+                                              lower_ML = iConfint.final[iConfint.final$method == "ML","lower"],
+                                              upper_ML = iConfint.final[iConfint.final$method == "ML","upper"],
+                                              estimate_ML = iConfint.final[iConfint.final$method == "ML","estimate"],
+                                              p.value_MUE = iConfint.final[iConfint.final$method == "MUE","p.value"],
+                                              lower_MUE = iConfint.final[iConfint.final$method == "MUE","lower"],
+                                              upper_MUE = iConfint.final[iConfint.final$method == "MUE","upper"],
+                                              estimate_MUE = iConfint.final[iConfint.final$method == "MUE","estimate"],
+                                              info = iInfo.final[1,"Interim"],
+                                              infoPC = iInfo.final[1,"Interim.pc"],
+                                              ck = iBoundary.final[1,"Cbound"],
+                                              decision = unname(coef(currentGSD[[iMeth]], type = "decision")["decision","stage 2"])
+                                              )
+         }
+     }
+                                         # }}}
+ 
+     stopComp <- Sys.time()
+                                         # {{{ Save results
+ 
+     outMerge <- do.call(rbind,lapply(method, function(iMeth){
+         iNames <- unique(c(names(out.interim[[iMeth]]),names(out.decision[[iMeth]]),names(out.final[[iMeth]])))
+         iMerge <- data.frame(matrix(NA, ncol = length(iNames)+3, nrow = 3, dimnames = list(NULL, c("method", "stage", "type", iNames))))
+         iMerge[1,c("method","stage","type",names(out.interim[[iMeth]]))] <- data.frame(method = iMeth, stage = 1, type = "interim", out.interim[[iMeth]]) 
+         iMerge[2,c("method","stage","type",names(out.decision[[iMeth]]))] <- data.frame(method = iMeth, stage = 1, type = "decision", out.decision[[iMeth]]) 
+         iMerge[3,c("method","stage","type",names(out.final[[iMeth]]))] <- data.frame(method = iMeth, stage = 2, type = "final", out.final[[iMeth]])
+         return(iMerge)
+     }))
+ 
+     ## outMerge[outMerge$method==3,]
+ 
+     out <- cbind(
+         ## results
+         outMerge,
+         ## simulation details
+         time.interim = thet,
+         seed=myseedi,             
+         nX1.interim = sum(!is.na(di$X1)),
+         nX2.interim = sum(!is.na(di$X2)),
+         nX3.interim = sum(!is.na(di$X3)),
+         ## computation time
+         computation.time=as.double(round(difftime(stopComp,startComp,units="secs"),3))
+     )
+     ## names(out) <- myColNames
+     RES <- rbind(RES,out)
+     save(RES,file=paste0(path.res,name,"(tempo)-",iter_sim,".rda"))
+                                         # }}}
+ }
[1] "seed 28308 for j=1 out of 250 (i.e. j=9751 in [9751;10000], as job id is i=40)"
Loading required namespace: nlme
[1] "seed 46731 for j=2 out of 250 (i.e. j=9752 in [9751;10000], as job id is i=40)"
[1] "seed 57213 for j=3 out of 250 (i.e. j=9753 in [9751;10000], as job id is i=40)"
[1] "seed 87785 for j=4 out of 250 (i.e. j=9754 in [9751;10000], as job id is i=40)"
[1] "seed 75566 for j=5 out of 250 (i.e. j=9755 in [9751;10000], as job id is i=40)"
[1] "seed 86504 for j=6 out of 250 (i.e. j=9756 in [9751;10000], as job id is i=40)"
[1] "seed 78928 for j=7 out of 250 (i.e. j=9757 in [9751;10000], as job id is i=40)"
[1] "seed 58866 for j=8 out of 250 (i.e. j=9758 in [9751;10000], as job id is i=40)"
[1] "seed 40903 for j=9 out of 250 (i.e. j=9759 in [9751;10000], as job id is i=40)"
[1] "seed 25093 for j=10 out of 250 (i.e. j=9760 in [9751;10000], as job id is i=40)"
[1] "seed 35219 for j=11 out of 250 (i.e. j=9761 in [9751;10000], as job id is i=40)"
[1] "seed 15520 for j=12 out of 250 (i.e. j=9762 in [9751;10000], as job id is i=40)"
[1] "seed 47002 for j=13 out of 250 (i.e. j=9763 in [9751;10000], as job id is i=40)"
[1] "seed 57835 for j=14 out of 250 (i.e. j=9764 in [9751;10000], as job id is i=40)"
[1] "seed 38467 for j=15 out of 250 (i.e. j=9765 in [9751;10000], as job id is i=40)"
[1] "seed 76118 for j=16 out of 250 (i.e. j=9766 in [9751;10000], as job id is i=40)"
[1] "seed 77208 for j=17 out of 250 (i.e. j=9767 in [9751;10000], as job id is i=40)"
[1] "seed 56927 for j=18 out of 250 (i.e. j=9768 in [9751;10000], as job id is i=40)"
[1] "seed 83228 for j=19 out of 250 (i.e. j=9769 in [9751;10000], as job id is i=40)"
[1] "seed 91722 for j=20 out of 250 (i.e. j=9770 in [9751;10000], as job id is i=40)"
[1] "seed 30999 for j=21 out of 250 (i.e. j=9771 in [9751;10000], as job id is i=40)"
[1] "seed 58910 for j=22 out of 250 (i.e. j=9772 in [9751;10000], as job id is i=40)"
[1] "seed 40429 for j=23 out of 250 (i.e. j=9773 in [9751;10000], as job id is i=40)"
[1] "seed 91057 for j=24 out of 250 (i.e. j=9774 in [9751;10000], as job id is i=40)"
[1] "seed 43710 for j=25 out of 250 (i.e. j=9775 in [9751;10000], as job id is i=40)"
[1] "seed 90567 for j=26 out of 250 (i.e. j=9776 in [9751;10000], as job id is i=40)"
[1] "seed 87176 for j=27 out of 250 (i.e. j=9777 in [9751;10000], as job id is i=40)"
[1] "seed 93634 for j=28 out of 250 (i.e. j=9778 in [9751;10000], as job id is i=40)"
[1] "seed 37257 for j=29 out of 250 (i.e. j=9779 in [9751;10000], as job id is i=40)"
[1] "seed 68658 for j=30 out of 250 (i.e. j=9780 in [9751;10000], as job id is i=40)"
[1] "seed 75686 for j=31 out of 250 (i.e. j=9781 in [9751;10000], as job id is i=40)"
[1] "seed 35971 for j=32 out of 250 (i.e. j=9782 in [9751;10000], as job id is i=40)"
[1] "seed 23461 for j=33 out of 250 (i.e. j=9783 in [9751;10000], as job id is i=40)"
[1] "seed 20675 for j=34 out of 250 (i.e. j=9784 in [9751;10000], as job id is i=40)"
[1] "seed 16596 for j=35 out of 250 (i.e. j=9785 in [9751;10000], as job id is i=40)"
[1] "seed 13390 for j=36 out of 250 (i.e. j=9786 in [9751;10000], as job id is i=40)"
[1] "seed 6560 for j=37 out of 250 (i.e. j=9787 in [9751;10000], as job id is i=40)"
[1] "seed 99054 for j=38 out of 250 (i.e. j=9788 in [9751;10000], as job id is i=40)"
[1] "seed 63487 for j=39 out of 250 (i.e. j=9789 in [9751;10000], as job id is i=40)"
[1] "seed 94694 for j=40 out of 250 (i.e. j=9790 in [9751;10000], as job id is i=40)"
[1] "seed 15136 for j=41 out of 250 (i.e. j=9791 in [9751;10000], as job id is i=40)"
[1] "seed 96438 for j=42 out of 250 (i.e. j=9792 in [9751;10000], as job id is i=40)"
[1] "seed 28719 for j=43 out of 250 (i.e. j=9793 in [9751;10000], as job id is i=40)"
[1] "seed 26407 for j=44 out of 250 (i.e. j=9794 in [9751;10000], as job id is i=40)"
[1] "seed 44197 for j=45 out of 250 (i.e. j=9795 in [9751;10000], as job id is i=40)"
[1] "seed 28480 for j=46 out of 250 (i.e. j=9796 in [9751;10000], as job id is i=40)"
[1] "seed 65525 for j=47 out of 250 (i.e. j=9797 in [9751;10000], as job id is i=40)"
[1] "seed 52329 for j=48 out of 250 (i.e. j=9798 in [9751;10000], as job id is i=40)"
[1] "seed 8393 for j=49 out of 250 (i.e. j=9799 in [9751;10000], as job id is i=40)"
[1] "seed 8699 for j=50 out of 250 (i.e. j=9800 in [9751;10000], as job id is i=40)"
[1] "seed 77528 for j=51 out of 250 (i.e. j=9801 in [9751;10000], as job id is i=40)"
[1] "seed 53963 for j=52 out of 250 (i.e. j=9802 in [9751;10000], as job id is i=40)"
[1] "seed 26929 for j=53 out of 250 (i.e. j=9803 in [9751;10000], as job id is i=40)"
[1] "seed 17072 for j=54 out of 250 (i.e. j=9804 in [9751;10000], as job id is i=40)"
[1] "seed 73934 for j=55 out of 250 (i.e. j=9805 in [9751;10000], as job id is i=40)"
[1] "seed 42860 for j=56 out of 250 (i.e. j=9806 in [9751;10000], as job id is i=40)"
[1] "seed 27808 for j=57 out of 250 (i.e. j=9807 in [9751;10000], as job id is i=40)"
[1] "seed 41987 for j=58 out of 250 (i.e. j=9808 in [9751;10000], as job id is i=40)"
[1] "seed 31426 for j=59 out of 250 (i.e. j=9809 in [9751;10000], as job id is i=40)"
[1] "seed 20672 for j=60 out of 250 (i.e. j=9810 in [9751;10000], as job id is i=40)"
[1] "seed 18452 for j=61 out of 250 (i.e. j=9811 in [9751;10000], as job id is i=40)"
[1] "seed 23524 for j=62 out of 250 (i.e. j=9812 in [9751;10000], as job id is i=40)"
[1] "seed 85584 for j=63 out of 250 (i.e. j=9813 in [9751;10000], as job id is i=40)"
[1] "seed 51767 for j=64 out of 250 (i.e. j=9814 in [9751;10000], as job id is i=40)"
[1] "seed 44842 for j=65 out of 250 (i.e. j=9815 in [9751;10000], as job id is i=40)"
[1] "seed 91501 for j=66 out of 250 (i.e. j=9816 in [9751;10000], as job id is i=40)"
[1] "seed 63292 for j=67 out of 250 (i.e. j=9817 in [9751;10000], as job id is i=40)"
[1] "seed 86246 for j=68 out of 250 (i.e. j=9818 in [9751;10000], as job id is i=40)"
[1] "seed 14859 for j=69 out of 250 (i.e. j=9819 in [9751;10000], as job id is i=40)"
[1] "seed 18781 for j=70 out of 250 (i.e. j=9820 in [9751;10000], as job id is i=40)"
[1] "seed 23828 for j=71 out of 250 (i.e. j=9821 in [9751;10000], as job id is i=40)"
Error in uniroot(function(x) { : 
  f() values at end points not of opposite sign
Calls: update ... update.delayedGSD -> updateBoundaries -> updateMethod1 -> uniroot
In addition: Warning messages:
1: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

2: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

3: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

4: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

Execution halted
