
R version 4.1.2 (2021-11-01) -- "Bird Hippie"
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ### BATCH_simuMain.R --- 
> #----------------------------------------------------------------------
> ## Author: Paul Blanche
> ## Created: Mar  5 2021 (10:56) 
> ## Version: 
> ## Last-Updated: maj  6 2022 (10:22) 
> ##           By: Brice Ozenne
> ##     Update #: 512
> #----------------------------------------------------------------------
> ## 
> ### Commentary: 
> ## 
> ### Change Log:
> #----------------------------------------------------------------------
> ## 
> ### Code:
> 
> rm(list=ls())
>                                    # {{{ parameters
> ## * parameters
> name <- "ScenarioName" # To save the results
> method <- 1:2 # methods used to compute the boundaries
>                                         #---
> myseed <- 140786598
>                                         #--- to plan the trial ----
> NMC <- 250 # number of sequential simulations to run in parallel. Eg. with 250, then we can run 40 scripts in paralell to get N=10,000 runs in total.
> kMax <- 2  #max number of analyses (including final)
> alpha <- 0.025  #type I error (one sided)
> beta <- 0.2  #type II error
> informationRates <- c(0.5,1)  #planned  information rates
> rho_alpha <- 2  # rho parameter for alpha error spending function
> rho_beta <- 2  # rho parameter for beta error spending function
> ## deltaPower <- 0.75 # just to try another value when Id > Imax
> Id <- 0.55  #(expected) information rate at each decision analysis
> binding <- TRUE
>                                         #
>                                         #---- to generate data -----------
>                                         #
> block <- c(1,1,0,0) 
> allsd <- c(2.5,2.1,2.4) # sd, first from baseline measurement, then the two changes from baseline
> mean0 <- c(10,0,0) # mean placebo group (again, first is absolute value, then change from baseline)
> delta <- c(0,0.6,0.8) # treatment effect
> ar <- (0.86*2)*2 # orginial accrual rate from data from Corine is 0.86 per week, hence we multiply by 2 for by 14 days. As to low, we further multiply by 2
> cor011 <- -0.15 # ~ from data from Corine
> corij1 <- 0.68  # ~ from data from Corine
> cor0j1 <- -0.27  # ~ from data from Corine
> Miss11 <- 5/104 # miss both V1 and V2
> Miss12 <- 1/104 # miss V1 and but not V2
> Miss21 <- 6/104 # do not miss V1 and but miss V2
> Miss22 <- 92/104 # miss none
> PropForInterim <- 0.5 # Decide to have interim analysiz when PropForInterim % of all subjects have had the chance to have one follow-up measuement recorded in the data to be available for analysis.
> theDelta.t <- 1.50001 # time lag to process the data and make them ready to analyze after collecting them (unit is time between two follow-up visits)
> TimeFactor <- 14 ## number of days between two visits
>                                         #
>                                         #--- actually for both planing the trial  and generating data-----
>                                         #
>                                         #
> deltaPower <- abs(delta[3]) # effect (NOT Z-scale/unit, but outcome scale/unit!) that the study is powered for: should we choose ourselves or compute from other numbers above ???
> n <- ceiling(2*2*((allsd[3]/deltaPower)^2)*(qnorm(1-beta)-qnorm(alpha))^2) #104 with Corine's data # should we choose ourselves or compute from the above numbers ???
>                                         # inflate SS as required for interim
> 
> # {{{ Set seeds for parallel computing and reproducibility
> ## * Seed
> iter_sim <- as.numeric(Sys.getenv("SLURM_ARRAY_TASK_ID"))
> n.iter_sim <- as.numeric(Sys.getenv("SLURM_ARRAY_TASK_COUNT"))
> if(is.na(iter_sim)){iter_sim <- 2}
> if(is.na(n.iter_sim)){n.iter_sim <- 10}
> 
> set.seed(140786598)
> allseeds <- sample.int(n = 10*n.iter_sim*NMC, size = n.iter_sim*NMC, replace=FALSE) #x=1:(.Machine$integer.max) seems to be maximal possible
> # }}}
> 
> # {{{ set path to load and save and othe machine specific variables
> ## * path
> path <- "."
> path.res <- file.path(path,"Results","simuMain")
> if(dir.exists(path.res)==FALSE){
+     if(dir.exists(file.path(path,"Results"))==FALSE){
+     dir.create(file.path(path,"Results"))
+     }
+     dir.create(path.res)
+ }
> path.output <- file.path(path,"output","simuMain")
> if(dir.exists(path.output)==FALSE){
+     if(dir.exists(file.path(path,"output"))==FALSE){
+     dir.create(file.path(path,"output"))
+     }
+     dir.create(path.output)
+ }
> # }}}
> 
> 
> ## * libraries and functions
> library(DelayedGSD)
DelayedGSD version 0.0.2
> ## sourceDir <- function(path, trace = TRUE, ...) {
> ##     for (nm in list.files(path, pattern = "[.][RrSsQq]$")) {
> ##         if(trace) cat(nm,":")
> ##         source(file.path(path, nm), ...)
> ##         if(trace) cat("\n")
> ##     }
> ## }
> ## sourceDir(pathToLoad)
>     
> 
> ## * Compute inflation factor and sample size
> plannedB <- vector(mode = "list", length = 3)
> for(iMeth in method){ ## iMeth <- 1
+     plannedB[[iMeth]] <- CalcBoundaries(kMax=kMax,  
+                                         alpha=alpha, 
+                                         beta=beta,  
+                                         InfoR.i=informationRates,  
+                                         InfoR.d=c(Id,1),  
+                                         rho_alpha=rho_alpha,  
+                                         rho_beta=rho_beta,  
+                                         method=iMeth,  
+                                         cNotBelowFixedc=FALSE,
+                                         bindingFutility=binding,
+                                         delta=tail(delta,1))
+     ## summary(plannedB[[1]])
+     ## coef(plannedB[[iMeth]], type = "information")
+ }
Loading required namespace: gsDesign
Loading required package: mvtnorm
Loading required namespace: BB
> inflationFactor <- unlist(lapply(plannedB,function(iP){iP$planned$InflationFactor}))
> nGSD <- ceiling(n*inflationFactor)
> ##  plot(plannedB[[1]])
> 
> #
> # --- just to check---
> ## n
> ## InfoFixed <- ((qnorm(1-beta)-qnorm(alpha))/(deltaPower))^2
> ## InfoFixed
> ## n/(4*(allsd[3])^2)
> #---
> # }}}
> 
> 
> 
> 
> # {{{ technical details to loop
> RES <- NULL # initialize results to save
> allj <- ((iter_sim-1)*NMC + 1):(iter_sim*NMC) # indices of all iterations (replicates) for this job, accountng for the other jobs running in parallel
> # }}}
> 
> ## * Loop
> for(j in allj){ ## j <- 5 ## 5
+     startComp <- Sys.time()
+     myseedi <- allseeds[j]
+     # {{{ TRACE info (e.g. to check the Rout)
+     print(paste0("seed ",myseedi," for ","j=",which(j==allj)," out of ",NMC, " (i.e. j=",j," in [",(iter_sim-1)*NMC + 1,";",iter_sim*NMC,"], as job id is i=",iter_sim,")"))
+     # }}}
+     # {{{ Missing probabilities
+     MyMissProb <- matrix(c(Miss11,Miss12,Miss21,Miss22),ncol=2,nrow=2,byrow=TRUE) # to additionnally remove 1 more because some FASFL=N
+     colnames(MyMissProb) <- c("V2 missing","V2 not missing")
+     rownames(MyMissProb) <- c("V1 missing","V1 not missing")
+     # }}}
+ 
+                                         # {{{ generate data
+     ## ** simulate
+     res <- GenData(n=n, 
+                    N.fw=2,
+                    rand.block=block,
+                    allsd=allsd,
+                    mean0=mean0,
+                    delta=delta,
+                    ar=ar,
+                    cor.01.1=cor011,
+                    cor.ij.1=corij1,
+                    cor.0j.1=cor0j1,
+                    seed=myseedi,
+                    MissProb=MyMissProb,
+                    DigitsOutcome=2,
+                    TimeFactor=TimeFactor,
+                    DigitsTime=0
+                    )
+     d <- res$d
+     ## head(d,n=20)
+                                         # }}}
+                                         # {{{ reformat data like those of Corine
+     ## Make data long format
+     ## dd <- FormatAsCase(d)
+     ## head(dd)
+     ## summary(dd)
+                                         # }}}
+    
+                                         # {{{ make data available at interim
+                                         # Here we stop inclusion data collection for the interim analysis as soon as
+                                         # half of the participants have completed (or had the opportunity to complete) the follow-up 
+     thet <- d$t3[ceiling(n*PropForInterim)]
+     di <- SelectData(d,t=thet)
+     ## ddi <- FormatAsCase(di) # needed ????
+     ## head(d[d$id==52,])
+                                         # }}}
+     ## {{{ analyze data at at interim
+     ## ** interim
+     lmmI <- analyzeData(di, ddf = "nlme", data.decision = sum(d$t1 <= thet + theDelta.t*TimeFactor), getinfo = TRUE, trace = TRUE)
+     ## lmmI <- analyzeData(di, ddf = "nlme", getinfo = TRUE, trace = TRUE)
+ 
+     currentGSD <- vector(mode = "list", length = 3)
+     out.interim <- vector(mode = "list", length = 3)
+     for(iMeth in method){ ## iMeth <- 1
+ 
+         currentGSD[[iMeth]] <- update(plannedB[[iMeth]], delta = lmmI, trace = FALSE)
+ 
+         iConfint.interim <- confint(currentGSD[[iMeth]])
+         iInfo.interim <- coef(currentGSD[[iMeth]], type = "information")
+         iBoundary.interim <- coef(currentGSD[[iMeth]], type = "boundary")
+         iDecision.interim <- coef(currentGSD[[iMeth]], type = "decision")
+ 
+         out.interim[[iMeth]] <-  data.frame(statistic = iConfint.interim[1,"statistic"],
+                                             estimate_ML = iConfint.interim[1,"estimate"],
+                                             se_ML = iConfint.interim[1,"se"],
+                                             info = iInfo.interim[1,"Interim"],
+                                             infoPC = iInfo.interim[1,"Interim.pc"],
+                                             info.pred = iInfo.interim[1,"Decision"],
+                                             infoPC.pred = iInfo.interim[1,"Decision.pc"],
+                                             uk = iBoundary.interim[1,"Ebound"],
+                                             lk = iBoundary.interim[1,"Fbound"],
+                                             decision = iDecision.interim["decision","stage 1"],
+                                             reason = iDecision.interim["reason.interim","stage 1"])
+     }
+     ## currentGSD[[1]]
+     ## plot(currentGSD[[1]])
+ 
+     ## ** decision
+     dDecision <- d[which(d$t1 <= thet + theDelta.t*TimeFactor),]
+     lmmD <- analyzeData(dDecision, ddf = "nlme", getinfo = TRUE, trace = TRUE)
+     
+     out.decision <- vector(mode = "list", length = 3)
+     for(iMeth in method){ ## iMeth <- 1
+           
+         if(out.interim[[iMeth]]$decision == "stop"){
+             currentGSD[[iMeth]] <- update(currentGSD[[iMeth]], delta = lmmD, trace = FALSE)
+             ## plot(currentGSD[[iMeth]])
+ 
+             iConfint.decision <- confint(currentGSD[[iMeth]], method = c("ML","MUE"))
+             iInfo.decision <- coef(currentGSD[[iMeth]], type = "information")
+             iBoundary.decision <- coef(currentGSD[[iMeth]], type = "boundary")
+             iDecision.decision  <- coef(currentGSD[[iMeth]], type = "decision")
+ 
+             out.decision[[iMeth]] <- data.frame(statistic = iConfint.decision[1,"statistic"],
+                                                 p.value_ML = iConfint.decision[iConfint.decision$method == "ML","p.value"],
+                                                 lower_ML = iConfint.decision[iConfint.decision$method == "ML","lower"],
+                                                 upper_ML = iConfint.decision[iConfint.decision$method == "ML","upper"],
+                                                 estimate_ML = iConfint.decision[iConfint.decision$method == "ML","estimate"],
+                                                 p.value_MUE = iConfint.decision[iConfint.decision$method == "MUE","p.value"],
+                                                 lower_MUE = iConfint.decision[iConfint.decision$method == "MUE","lower"],
+                                                 upper_MUE = iConfint.decision[iConfint.decision$method == "MUE","upper"],
+                                                 estimate_MUE = iConfint.decision[iConfint.decision$method == "MUE","estimate"],
+                                                 info = iInfo.decision[1,"Interim"],
+                                                 infoPC = iInfo.decision[1,"Interim.pc"],
+                                                 ck = iBoundary.decision[1,"Cbound"],
+                                                 decision = unname(iDecision.decision["decision","stage 2"])
+                                                 )
+ 
+         }else{
+             ## update information
+             currentGSD[[iMeth]] <- update(currentGSD[[iMeth]], delta = lmmD, k = 1, type.k = "decision", trace = FALSE)
+ 
+             iInfo.decision <- coef(currentGSD[[iMeth]], type = "information")
+             iBoundary.decision <- coef(currentGSD[[iMeth]], type = "boundary")
+ 
+             out.decision[[iMeth]] <- data.frame(statistic = NA,
+                                                 p.value_ML = NA,
+                                                 lower_ML = NA,
+                                                 upper_ML = NA,
+                                                 estimate_ML = NA,
+                                                 p.value_MUE = NA,
+                                                 lower_MUE = NA,
+                                                 upper_MUE = NA,
+                                                 estimate_MUE = NA,
+                                                 info = iInfo.decision[1,"Decision"],
+                                                 infoPC = iInfo.decision[1,"Decision.pc"],
+                                                 ck = iBoundary.decision[1,"Cbound"],
+                                                 decision = NA)
+         }
+     }
+                                         # }}}
+                                         # {{{ Analyze data at decision
+ 
+     ## ** finale
+     dFinal <- d
+     lmmF <- analyzeData(dFinal, ddf = "nlme", getinfo = TRUE, trace = TRUE)
+ 
+     out.final <- vector(mode = "list", length = 3)
+     for(iMeth in method){ ## iMeth <- 1
+         if(out.interim[[iMeth]]$decision == "stop"){
+             out.final[[iMeth]] <- data.frame(statistic = NA,
+                                              p.value_ML = NA,
+                                              lower_ML = NA,
+                                              upper_ML = NA,
+                                              estimate_ML = NA,
+                                              p.value_MUE = NA,
+                                              lower_MUE = NA,
+                                              upper_MUE = NA,
+                                              estimate_MUE = NA,
+                                              info = NA,
+                                              infoPC = NA,
+                                              ck = NA,
+                                              decision = NA)
+ 
+         }else{
+             currentGSD[[iMeth]] <- update(currentGSD[[iMeth]], delta = lmmF, trace = FALSE)
+ 
+             ## plot(test)
+             ## summary(test)
+             iConfint.final <- confint(currentGSD[[iMeth]], method = c("ML","MUE"))
+             iInfo.final <- coef(currentGSD[[iMeth]], type = "information")
+             iBoundary.final <- coef(currentGSD[[iMeth]], type = "boundary")
+             iDecision.final  <- coef(currentGSD[[iMeth]], type = "decision")
+ 
+             out.final[[iMeth]] <- data.frame(statistic = iConfint.final[1,"statistic"],
+                                              p.value_ML = iConfint.final[iConfint.final$method == "ML","p.value"],
+                                              lower_ML = iConfint.final[iConfint.final$method == "ML","lower"],
+                                              upper_ML = iConfint.final[iConfint.final$method == "ML","upper"],
+                                              estimate_ML = iConfint.final[iConfint.final$method == "ML","estimate"],
+                                              p.value_MUE = iConfint.final[iConfint.final$method == "MUE","p.value"],
+                                              lower_MUE = iConfint.final[iConfint.final$method == "MUE","lower"],
+                                              upper_MUE = iConfint.final[iConfint.final$method == "MUE","upper"],
+                                              estimate_MUE = iConfint.final[iConfint.final$method == "MUE","estimate"],
+                                              info = iInfo.final[1,"Interim"],
+                                              infoPC = iInfo.final[1,"Interim.pc"],
+                                              ck = iBoundary.final[1,"Cbound"],
+                                              decision = unname(coef(currentGSD[[iMeth]], type = "decision")["decision","stage 2"])
+                                              )
+         }
+     }
+                                         # }}}
+ 
+     stopComp <- Sys.time()
+                                         # {{{ Save results
+ 
+     outMerge <- do.call(rbind,lapply(method, function(iMeth){
+         iNames <- unique(c(names(out.interim[[iMeth]]),names(out.decision[[iMeth]]),names(out.final[[iMeth]])))
+         iMerge <- data.frame(matrix(NA, ncol = length(iNames)+3, nrow = 3, dimnames = list(NULL, c("method", "stage", "type", iNames))))
+         iMerge[1,c("method","stage","type",names(out.interim[[iMeth]]))] <- data.frame(method = iMeth, stage = 1, type = "interim", out.interim[[iMeth]]) 
+         iMerge[2,c("method","stage","type",names(out.decision[[iMeth]]))] <- data.frame(method = iMeth, stage = 1, type = "decision", out.decision[[iMeth]]) 
+         iMerge[3,c("method","stage","type",names(out.final[[iMeth]]))] <- data.frame(method = iMeth, stage = 2, type = "final", out.final[[iMeth]])
+         return(iMerge)
+     }))
+ 
+     ## outMerge[outMerge$method==3,]
+ 
+     out <- cbind(
+         ## results
+         outMerge,
+         ## simulation details
+         time.interim = thet,
+         seed=myseedi,             
+         nX1.interim = sum(!is.na(di$X1)),
+         nX2.interim = sum(!is.na(di$X2)),
+         nX3.interim = sum(!is.na(di$X3)),
+         ## computation time
+         computation.time=as.double(round(difftime(stopComp,startComp,units="secs"),3))
+     )
+     ## names(out) <- myColNames
+     RES <- rbind(RES,out)
+     save(RES,file=paste0(path.res,name,"(tempo)-",iter_sim,".rda"))
+                                         # }}}
+ }
[1] "seed 86965 for j=1 out of 250 (i.e. j=1001 in [1001;1250], as job id is i=5)"
Loading required namespace: nlme
[1] "seed 12691 for j=2 out of 250 (i.e. j=1002 in [1001;1250], as job id is i=5)"
[1] "seed 85690 for j=3 out of 250 (i.e. j=1003 in [1001;1250], as job id is i=5)"
[1] "seed 99158 for j=4 out of 250 (i.e. j=1004 in [1001;1250], as job id is i=5)"
[1] "seed 69134 for j=5 out of 250 (i.e. j=1005 in [1001;1250], as job id is i=5)"
[1] "seed 18615 for j=6 out of 250 (i.e. j=1006 in [1001;1250], as job id is i=5)"
[1] "seed 6002 for j=7 out of 250 (i.e. j=1007 in [1001;1250], as job id is i=5)"
[1] "seed 56268 for j=8 out of 250 (i.e. j=1008 in [1001;1250], as job id is i=5)"
[1] "seed 48062 for j=9 out of 250 (i.e. j=1009 in [1001;1250], as job id is i=5)"
[1] "seed 7905 for j=10 out of 250 (i.e. j=1010 in [1001;1250], as job id is i=5)"
[1] "seed 53206 for j=11 out of 250 (i.e. j=1011 in [1001;1250], as job id is i=5)"
[1] "seed 59485 for j=12 out of 250 (i.e. j=1012 in [1001;1250], as job id is i=5)"
[1] "seed 5145 for j=13 out of 250 (i.e. j=1013 in [1001;1250], as job id is i=5)"
[1] "seed 88258 for j=14 out of 250 (i.e. j=1014 in [1001;1250], as job id is i=5)"
[1] "seed 41454 for j=15 out of 250 (i.e. j=1015 in [1001;1250], as job id is i=5)"
[1] "seed 7512 for j=16 out of 250 (i.e. j=1016 in [1001;1250], as job id is i=5)"
[1] "seed 10682 for j=17 out of 250 (i.e. j=1017 in [1001;1250], as job id is i=5)"
[1] "seed 85519 for j=18 out of 250 (i.e. j=1018 in [1001;1250], as job id is i=5)"
[1] "seed 98972 for j=19 out of 250 (i.e. j=1019 in [1001;1250], as job id is i=5)"
[1] "seed 13331 for j=20 out of 250 (i.e. j=1020 in [1001;1250], as job id is i=5)"
[1] "seed 14312 for j=21 out of 250 (i.e. j=1021 in [1001;1250], as job id is i=5)"
[1] "seed 94776 for j=22 out of 250 (i.e. j=1022 in [1001;1250], as job id is i=5)"
[1] "seed 96276 for j=23 out of 250 (i.e. j=1023 in [1001;1250], as job id is i=5)"
[1] "seed 77625 for j=24 out of 250 (i.e. j=1024 in [1001;1250], as job id is i=5)"
[1] "seed 4570 for j=25 out of 250 (i.e. j=1025 in [1001;1250], as job id is i=5)"
[1] "seed 35798 for j=26 out of 250 (i.e. j=1026 in [1001;1250], as job id is i=5)"
[1] "seed 56218 for j=27 out of 250 (i.e. j=1027 in [1001;1250], as job id is i=5)"
[1] "seed 23530 for j=28 out of 250 (i.e. j=1028 in [1001;1250], as job id is i=5)"
[1] "seed 19932 for j=29 out of 250 (i.e. j=1029 in [1001;1250], as job id is i=5)"
[1] "seed 61422 for j=30 out of 250 (i.e. j=1030 in [1001;1250], as job id is i=5)"
[1] "seed 90505 for j=31 out of 250 (i.e. j=1031 in [1001;1250], as job id is i=5)"
[1] "seed 54196 for j=32 out of 250 (i.e. j=1032 in [1001;1250], as job id is i=5)"
[1] "seed 6987 for j=33 out of 250 (i.e. j=1033 in [1001;1250], as job id is i=5)"
[1] "seed 72519 for j=34 out of 250 (i.e. j=1034 in [1001;1250], as job id is i=5)"
[1] "seed 32486 for j=35 out of 250 (i.e. j=1035 in [1001;1250], as job id is i=5)"
[1] "seed 4441 for j=36 out of 250 (i.e. j=1036 in [1001;1250], as job id is i=5)"
[1] "seed 87174 for j=37 out of 250 (i.e. j=1037 in [1001;1250], as job id is i=5)"
[1] "seed 92044 for j=38 out of 250 (i.e. j=1038 in [1001;1250], as job id is i=5)"
[1] "seed 74251 for j=39 out of 250 (i.e. j=1039 in [1001;1250], as job id is i=5)"
[1] "seed 40356 for j=40 out of 250 (i.e. j=1040 in [1001;1250], as job id is i=5)"
[1] "seed 66767 for j=41 out of 250 (i.e. j=1041 in [1001;1250], as job id is i=5)"
[1] "seed 44780 for j=42 out of 250 (i.e. j=1042 in [1001;1250], as job id is i=5)"
[1] "seed 12700 for j=43 out of 250 (i.e. j=1043 in [1001;1250], as job id is i=5)"
[1] "seed 68029 for j=44 out of 250 (i.e. j=1044 in [1001;1250], as job id is i=5)"
[1] "seed 4641 for j=45 out of 250 (i.e. j=1045 in [1001;1250], as job id is i=5)"
[1] "seed 23417 for j=46 out of 250 (i.e. j=1046 in [1001;1250], as job id is i=5)"
[1] "seed 74344 for j=47 out of 250 (i.e. j=1047 in [1001;1250], as job id is i=5)"
[1] "seed 57402 for j=48 out of 250 (i.e. j=1048 in [1001;1250], as job id is i=5)"
[1] "seed 75318 for j=49 out of 250 (i.e. j=1049 in [1001;1250], as job id is i=5)"
[1] "seed 52929 for j=50 out of 250 (i.e. j=1050 in [1001;1250], as job id is i=5)"
[1] "seed 4933 for j=51 out of 250 (i.e. j=1051 in [1001;1250], as job id is i=5)"
[1] "seed 9814 for j=52 out of 250 (i.e. j=1052 in [1001;1250], as job id is i=5)"
[1] "seed 9209 for j=53 out of 250 (i.e. j=1053 in [1001;1250], as job id is i=5)"
[1] "seed 90164 for j=54 out of 250 (i.e. j=1054 in [1001;1250], as job id is i=5)"
[1] "seed 1681 for j=55 out of 250 (i.e. j=1055 in [1001;1250], as job id is i=5)"
[1] "seed 13192 for j=56 out of 250 (i.e. j=1056 in [1001;1250], as job id is i=5)"
[1] "seed 63114 for j=57 out of 250 (i.e. j=1057 in [1001;1250], as job id is i=5)"
Error in uniroot(function(x) { : 
  f() values at end points not of opposite sign
Calls: update ... update.delayedGSD -> updateBoundaries -> updateMethod1 -> uniroot
In addition: Warning messages:
1: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

2: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

Execution halted
