
R version 4.1.2 (2021-11-01) -- "Bird Hippie"
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ### BATCH_simuMain.R --- 
> #----------------------------------------------------------------------
> ## Author: Paul Blanche
> ## Created: Mar  5 2021 (10:56) 
> ## Version: 
> ## Last-Updated: maj  6 2022 (10:22) 
> ##           By: Brice Ozenne
> ##     Update #: 512
> #----------------------------------------------------------------------
> ## 
> ### Commentary: 
> ## 
> ### Change Log:
> #----------------------------------------------------------------------
> ## 
> ### Code:
> 
> rm(list=ls())
>                                    # {{{ parameters
> ## * parameters
> name <- "ScenarioName" # To save the results
> method <- 1:2 # methods used to compute the boundaries
>                                         #---
> myseed <- 140786598
>                                         #--- to plan the trial ----
> NMC <- 250 # number of sequential simulations to run in parallel. Eg. with 250, then we can run 40 scripts in paralell to get N=10,000 runs in total.
> kMax <- 2  #max number of analyses (including final)
> alpha <- 0.025  #type I error (one sided)
> beta <- 0.2  #type II error
> informationRates <- c(0.5,1)  #planned  information rates
> rho_alpha <- 2  # rho parameter for alpha error spending function
> rho_beta <- 2  # rho parameter for beta error spending function
> ## deltaPower <- 0.75 # just to try another value when Id > Imax
> Id <- 0.55  #(expected) information rate at each decision analysis
> binding <- TRUE
>                                         #
>                                         #---- to generate data -----------
>                                         #
> block <- c(1,1,0,0) 
> allsd <- c(2.5,2.1,2.4) # sd, first from baseline measurement, then the two changes from baseline
> mean0 <- c(10,0,0) # mean placebo group (again, first is absolute value, then change from baseline)
> delta <- c(0,0.6,0.8) # treatment effect
> ar <- (0.86*2)*2 # orginial accrual rate from data from Corine is 0.86 per week, hence we multiply by 2 for by 14 days. As to low, we further multiply by 2
> cor011 <- -0.15 # ~ from data from Corine
> corij1 <- 0.68  # ~ from data from Corine
> cor0j1 <- -0.27  # ~ from data from Corine
> Miss11 <- 5/104 # miss both V1 and V2
> Miss12 <- 1/104 # miss V1 and but not V2
> Miss21 <- 6/104 # do not miss V1 and but miss V2
> Miss22 <- 92/104 # miss none
> PropForInterim <- 0.5 # Decide to have interim analysiz when PropForInterim % of all subjects have had the chance to have one follow-up measuement recorded in the data to be available for analysis.
> theDelta.t <- 1.50001 # time lag to process the data and make them ready to analyze after collecting them (unit is time between two follow-up visits)
> TimeFactor <- 14 ## number of days between two visits
>                                         #
>                                         #--- actually for both planing the trial  and generating data-----
>                                         #
>                                         #
> deltaPower <- abs(delta[3]) # effect (NOT Z-scale/unit, but outcome scale/unit!) that the study is powered for: should we choose ourselves or compute from other numbers above ???
> n <- ceiling(2*2*((allsd[3]/deltaPower)^2)*(qnorm(1-beta)-qnorm(alpha))^2) #104 with Corine's data # should we choose ourselves or compute from the above numbers ???
>                                         # inflate SS as required for interim
> 
> # {{{ Set seeds for parallel computing and reproducibility
> ## * Seed
> iter_sim <- as.numeric(Sys.getenv("SLURM_ARRAY_TASK_ID"))
> n.iter_sim <- as.numeric(Sys.getenv("SLURM_ARRAY_TASK_COUNT"))
> if(is.na(iter_sim)){iter_sim <- 2}
> if(is.na(n.iter_sim)){n.iter_sim <- 10}
> 
> set.seed(140786598)
> allseeds <- sample.int(n = 10*n.iter_sim*NMC, size = n.iter_sim*NMC, replace=FALSE) #x=1:(.Machine$integer.max) seems to be maximal possible
> # }}}
> 
> # {{{ set path to load and save and othe machine specific variables
> ## * path
> path <- "."
> path.res <- file.path(path,"Results","simuMain")
> if(dir.exists(path.res)==FALSE){
+     if(dir.exists(file.path(path,"Results"))==FALSE){
+     dir.create(file.path(path,"Results"))
+     }
+     dir.create(path.res)
+ }
> path.output <- file.path(path,"output","simuMain")
> if(dir.exists(path.output)==FALSE){
+     if(dir.exists(file.path(path,"output"))==FALSE){
+     dir.create(file.path(path,"output"))
+     }
+     dir.create(path.output)
+ }
> # }}}
> 
> 
> ## * libraries and functions
> library(DelayedGSD)
DelayedGSD version 0.0.2
> ## sourceDir <- function(path, trace = TRUE, ...) {
> ##     for (nm in list.files(path, pattern = "[.][RrSsQq]$")) {
> ##         if(trace) cat(nm,":")
> ##         source(file.path(path, nm), ...)
> ##         if(trace) cat("\n")
> ##     }
> ## }
> ## sourceDir(pathToLoad)
>     
> 
> ## * Compute inflation factor and sample size
> plannedB <- vector(mode = "list", length = 3)
> for(iMeth in method){ ## iMeth <- 1
+     plannedB[[iMeth]] <- CalcBoundaries(kMax=kMax,  
+                                         alpha=alpha, 
+                                         beta=beta,  
+                                         InfoR.i=informationRates,  
+                                         InfoR.d=c(Id,1),  
+                                         rho_alpha=rho_alpha,  
+                                         rho_beta=rho_beta,  
+                                         method=iMeth,  
+                                         cNotBelowFixedc=FALSE,
+                                         bindingFutility=binding,
+                                         delta=tail(delta,1))
+     ## summary(plannedB[[1]])
+     ## coef(plannedB[[iMeth]], type = "information")
+ }
Loading required namespace: gsDesign
Loading required package: mvtnorm
Loading required namespace: BB
> inflationFactor <- unlist(lapply(plannedB,function(iP){iP$planned$InflationFactor}))
> nGSD <- ceiling(n*inflationFactor)
> ##  plot(plannedB[[1]])
> 
> #
> # --- just to check---
> ## n
> ## InfoFixed <- ((qnorm(1-beta)-qnorm(alpha))/(deltaPower))^2
> ## InfoFixed
> ## n/(4*(allsd[3])^2)
> #---
> # }}}
> 
> 
> 
> 
> # {{{ technical details to loop
> RES <- NULL # initialize results to save
> allj <- ((iter_sim-1)*NMC + 1):(iter_sim*NMC) # indices of all iterations (replicates) for this job, accountng for the other jobs running in parallel
> # }}}
> 
> ## * Loop
> for(j in allj){ ## j <- 5 ## 5
+     startComp <- Sys.time()
+     myseedi <- allseeds[j]
+     # {{{ TRACE info (e.g. to check the Rout)
+     print(paste0("seed ",myseedi," for ","j=",which(j==allj)," out of ",NMC, " (i.e. j=",j," in [",(iter_sim-1)*NMC + 1,";",iter_sim*NMC,"], as job id is i=",iter_sim,")"))
+     # }}}
+     # {{{ Missing probabilities
+     MyMissProb <- matrix(c(Miss11,Miss12,Miss21,Miss22),ncol=2,nrow=2,byrow=TRUE) # to additionnally remove 1 more because some FASFL=N
+     colnames(MyMissProb) <- c("V2 missing","V2 not missing")
+     rownames(MyMissProb) <- c("V1 missing","V1 not missing")
+     # }}}
+ 
+                                         # {{{ generate data
+     ## ** simulate
+     res <- GenData(n=n, 
+                    N.fw=2,
+                    rand.block=block,
+                    allsd=allsd,
+                    mean0=mean0,
+                    delta=delta,
+                    ar=ar,
+                    cor.01.1=cor011,
+                    cor.ij.1=corij1,
+                    cor.0j.1=cor0j1,
+                    seed=myseedi,
+                    MissProb=MyMissProb,
+                    DigitsOutcome=2,
+                    TimeFactor=TimeFactor,
+                    DigitsTime=0
+                    )
+     d <- res$d
+     ## head(d,n=20)
+                                         # }}}
+                                         # {{{ reformat data like those of Corine
+     ## Make data long format
+     ## dd <- FormatAsCase(d)
+     ## head(dd)
+     ## summary(dd)
+                                         # }}}
+    
+                                         # {{{ make data available at interim
+                                         # Here we stop inclusion data collection for the interim analysis as soon as
+                                         # half of the participants have completed (or had the opportunity to complete) the follow-up 
+     thet <- d$t3[ceiling(n*PropForInterim)]
+     di <- SelectData(d,t=thet)
+     ## ddi <- FormatAsCase(di) # needed ????
+     ## head(d[d$id==52,])
+                                         # }}}
+     ## {{{ analyze data at at interim
+     ## ** interim
+     lmmI <- analyzeData(di, ddf = "nlme", data.decision = sum(d$t1 <= thet + theDelta.t*TimeFactor), getinfo = TRUE, trace = TRUE)
+     ## lmmI <- analyzeData(di, ddf = "nlme", getinfo = TRUE, trace = TRUE)
+ 
+     currentGSD <- vector(mode = "list", length = 3)
+     out.interim <- vector(mode = "list", length = 3)
+     for(iMeth in method){ ## iMeth <- 1
+ 
+         currentGSD[[iMeth]] <- update(plannedB[[iMeth]], delta = lmmI, trace = FALSE)
+ 
+         iConfint.interim <- confint(currentGSD[[iMeth]])
+         iInfo.interim <- coef(currentGSD[[iMeth]], type = "information")
+         iBoundary.interim <- coef(currentGSD[[iMeth]], type = "boundary")
+         iDecision.interim <- coef(currentGSD[[iMeth]], type = "decision")
+ 
+         out.interim[[iMeth]] <-  data.frame(statistic = iConfint.interim[1,"statistic"],
+                                             estimate_ML = iConfint.interim[1,"estimate"],
+                                             se_ML = iConfint.interim[1,"se"],
+                                             info = iInfo.interim[1,"Interim"],
+                                             infoPC = iInfo.interim[1,"Interim.pc"],
+                                             info.pred = iInfo.interim[1,"Decision"],
+                                             infoPC.pred = iInfo.interim[1,"Decision.pc"],
+                                             uk = iBoundary.interim[1,"Ebound"],
+                                             lk = iBoundary.interim[1,"Fbound"],
+                                             decision = iDecision.interim["decision","stage 1"],
+                                             reason = iDecision.interim["reason.interim","stage 1"])
+     }
+     ## currentGSD[[1]]
+     ## plot(currentGSD[[1]])
+ 
+     ## ** decision
+     dDecision <- d[which(d$t1 <= thet + theDelta.t*TimeFactor),]
+     lmmD <- analyzeData(dDecision, ddf = "nlme", getinfo = TRUE, trace = TRUE)
+     
+     out.decision <- vector(mode = "list", length = 3)
+     for(iMeth in method){ ## iMeth <- 1
+           
+         if(out.interim[[iMeth]]$decision == "stop"){
+             currentGSD[[iMeth]] <- update(currentGSD[[iMeth]], delta = lmmD, trace = FALSE)
+             ## plot(currentGSD[[iMeth]])
+ 
+             iConfint.decision <- confint(currentGSD[[iMeth]], method = c("ML","MUE"))
+             iInfo.decision <- coef(currentGSD[[iMeth]], type = "information")
+             iBoundary.decision <- coef(currentGSD[[iMeth]], type = "boundary")
+             iDecision.decision  <- coef(currentGSD[[iMeth]], type = "decision")
+ 
+             out.decision[[iMeth]] <- data.frame(statistic = iConfint.decision[1,"statistic"],
+                                                 p.value_ML = iConfint.decision[iConfint.decision$method == "ML","p.value"],
+                                                 lower_ML = iConfint.decision[iConfint.decision$method == "ML","lower"],
+                                                 upper_ML = iConfint.decision[iConfint.decision$method == "ML","upper"],
+                                                 estimate_ML = iConfint.decision[iConfint.decision$method == "ML","estimate"],
+                                                 p.value_MUE = iConfint.decision[iConfint.decision$method == "MUE","p.value"],
+                                                 lower_MUE = iConfint.decision[iConfint.decision$method == "MUE","lower"],
+                                                 upper_MUE = iConfint.decision[iConfint.decision$method == "MUE","upper"],
+                                                 estimate_MUE = iConfint.decision[iConfint.decision$method == "MUE","estimate"],
+                                                 info = iInfo.decision[1,"Interim"],
+                                                 infoPC = iInfo.decision[1,"Interim.pc"],
+                                                 ck = iBoundary.decision[1,"Cbound"],
+                                                 decision = unname(iDecision.decision["decision","stage 2"])
+                                                 )
+ 
+         }else{
+             ## update information
+             currentGSD[[iMeth]] <- update(currentGSD[[iMeth]], delta = lmmD, k = 1, type.k = "decision", trace = FALSE)
+ 
+             iInfo.decision <- coef(currentGSD[[iMeth]], type = "information")
+             iBoundary.decision <- coef(currentGSD[[iMeth]], type = "boundary")
+ 
+             out.decision[[iMeth]] <- data.frame(statistic = NA,
+                                                 p.value_ML = NA,
+                                                 lower_ML = NA,
+                                                 upper_ML = NA,
+                                                 estimate_ML = NA,
+                                                 p.value_MUE = NA,
+                                                 lower_MUE = NA,
+                                                 upper_MUE = NA,
+                                                 estimate_MUE = NA,
+                                                 info = iInfo.decision[1,"Decision"],
+                                                 infoPC = iInfo.decision[1,"Decision.pc"],
+                                                 ck = iBoundary.decision[1,"Cbound"],
+                                                 decision = NA)
+         }
+     }
+                                         # }}}
+                                         # {{{ Analyze data at decision
+ 
+     ## ** finale
+     dFinal <- d
+     lmmF <- analyzeData(dFinal, ddf = "nlme", getinfo = TRUE, trace = TRUE)
+ 
+     out.final <- vector(mode = "list", length = 3)
+     for(iMeth in method){ ## iMeth <- 1
+         if(out.interim[[iMeth]]$decision == "stop"){
+             out.final[[iMeth]] <- data.frame(statistic = NA,
+                                              p.value_ML = NA,
+                                              lower_ML = NA,
+                                              upper_ML = NA,
+                                              estimate_ML = NA,
+                                              p.value_MUE = NA,
+                                              lower_MUE = NA,
+                                              upper_MUE = NA,
+                                              estimate_MUE = NA,
+                                              info = NA,
+                                              infoPC = NA,
+                                              ck = NA,
+                                              decision = NA)
+ 
+         }else{
+             currentGSD[[iMeth]] <- update(currentGSD[[iMeth]], delta = lmmF, trace = FALSE)
+ 
+             ## plot(test)
+             ## summary(test)
+             iConfint.final <- confint(currentGSD[[iMeth]], method = c("ML","MUE"))
+             iInfo.final <- coef(currentGSD[[iMeth]], type = "information")
+             iBoundary.final <- coef(currentGSD[[iMeth]], type = "boundary")
+             iDecision.final  <- coef(currentGSD[[iMeth]], type = "decision")
+ 
+             out.final[[iMeth]] <- data.frame(statistic = iConfint.final[1,"statistic"],
+                                              p.value_ML = iConfint.final[iConfint.final$method == "ML","p.value"],
+                                              lower_ML = iConfint.final[iConfint.final$method == "ML","lower"],
+                                              upper_ML = iConfint.final[iConfint.final$method == "ML","upper"],
+                                              estimate_ML = iConfint.final[iConfint.final$method == "ML","estimate"],
+                                              p.value_MUE = iConfint.final[iConfint.final$method == "MUE","p.value"],
+                                              lower_MUE = iConfint.final[iConfint.final$method == "MUE","lower"],
+                                              upper_MUE = iConfint.final[iConfint.final$method == "MUE","upper"],
+                                              estimate_MUE = iConfint.final[iConfint.final$method == "MUE","estimate"],
+                                              info = iInfo.final[1,"Interim"],
+                                              infoPC = iInfo.final[1,"Interim.pc"],
+                                              ck = iBoundary.final[1,"Cbound"],
+                                              decision = unname(coef(currentGSD[[iMeth]], type = "decision")["decision","stage 2"])
+                                              )
+         }
+     }
+                                         # }}}
+ 
+     stopComp <- Sys.time()
+                                         # {{{ Save results
+ 
+     outMerge <- do.call(rbind,lapply(method, function(iMeth){
+         iNames <- unique(c(names(out.interim[[iMeth]]),names(out.decision[[iMeth]]),names(out.final[[iMeth]])))
+         iMerge <- data.frame(matrix(NA, ncol = length(iNames)+3, nrow = 3, dimnames = list(NULL, c("method", "stage", "type", iNames))))
+         iMerge[1,c("method","stage","type",names(out.interim[[iMeth]]))] <- data.frame(method = iMeth, stage = 1, type = "interim", out.interim[[iMeth]]) 
+         iMerge[2,c("method","stage","type",names(out.decision[[iMeth]]))] <- data.frame(method = iMeth, stage = 1, type = "decision", out.decision[[iMeth]]) 
+         iMerge[3,c("method","stage","type",names(out.final[[iMeth]]))] <- data.frame(method = iMeth, stage = 2, type = "final", out.final[[iMeth]])
+         return(iMerge)
+     }))
+ 
+     ## outMerge[outMerge$method==3,]
+ 
+     out <- cbind(
+         ## results
+         outMerge,
+         ## simulation details
+         time.interim = thet,
+         seed=myseedi,             
+         nX1.interim = sum(!is.na(di$X1)),
+         nX2.interim = sum(!is.na(di$X2)),
+         nX3.interim = sum(!is.na(di$X3)),
+         ## computation time
+         computation.time=as.double(round(difftime(stopComp,startComp,units="secs"),3))
+     )
+     ## names(out) <- myColNames
+     RES <- rbind(RES,out)
+     save(RES,file=paste0(path.res,name,"(tempo)-",iter_sim,".rda"))
+                                         # }}}
+ }
[1] "seed 22688 for j=1 out of 250 (i.e. j=4501 in [4501;4750], as job id is i=19)"
Loading required namespace: nlme
[1] "seed 3361 for j=2 out of 250 (i.e. j=4502 in [4501;4750], as job id is i=19)"
[1] "seed 2399 for j=3 out of 250 (i.e. j=4503 in [4501;4750], as job id is i=19)"
[1] "seed 81157 for j=4 out of 250 (i.e. j=4504 in [4501;4750], as job id is i=19)"
[1] "seed 2645 for j=5 out of 250 (i.e. j=4505 in [4501;4750], as job id is i=19)"
[1] "seed 50032 for j=6 out of 250 (i.e. j=4506 in [4501;4750], as job id is i=19)"
[1] "seed 358 for j=7 out of 250 (i.e. j=4507 in [4501;4750], as job id is i=19)"
[1] "seed 96333 for j=8 out of 250 (i.e. j=4508 in [4501;4750], as job id is i=19)"
[1] "seed 93454 for j=9 out of 250 (i.e. j=4509 in [4501;4750], as job id is i=19)"
[1] "seed 16515 for j=10 out of 250 (i.e. j=4510 in [4501;4750], as job id is i=19)"
[1] "seed 54102 for j=11 out of 250 (i.e. j=4511 in [4501;4750], as job id is i=19)"
[1] "seed 67065 for j=12 out of 250 (i.e. j=4512 in [4501;4750], as job id is i=19)"
[1] "seed 20786 for j=13 out of 250 (i.e. j=4513 in [4501;4750], as job id is i=19)"
[1] "seed 31273 for j=14 out of 250 (i.e. j=4514 in [4501;4750], as job id is i=19)"
[1] "seed 511 for j=15 out of 250 (i.e. j=4515 in [4501;4750], as job id is i=19)"
[1] "seed 87624 for j=16 out of 250 (i.e. j=4516 in [4501;4750], as job id is i=19)"
[1] "seed 91136 for j=17 out of 250 (i.e. j=4517 in [4501;4750], as job id is i=19)"
[1] "seed 57918 for j=18 out of 250 (i.e. j=4518 in [4501;4750], as job id is i=19)"
[1] "seed 41810 for j=19 out of 250 (i.e. j=4519 in [4501;4750], as job id is i=19)"
[1] "seed 70399 for j=20 out of 250 (i.e. j=4520 in [4501;4750], as job id is i=19)"
[1] "seed 38474 for j=21 out of 250 (i.e. j=4521 in [4501;4750], as job id is i=19)"
[1] "seed 3737 for j=22 out of 250 (i.e. j=4522 in [4501;4750], as job id is i=19)"
[1] "seed 64930 for j=23 out of 250 (i.e. j=4523 in [4501;4750], as job id is i=19)"
[1] "seed 36627 for j=24 out of 250 (i.e. j=4524 in [4501;4750], as job id is i=19)"
[1] "seed 8339 for j=25 out of 250 (i.e. j=4525 in [4501;4750], as job id is i=19)"
[1] "seed 7826 for j=26 out of 250 (i.e. j=4526 in [4501;4750], as job id is i=19)"
[1] "seed 18427 for j=27 out of 250 (i.e. j=4527 in [4501;4750], as job id is i=19)"
[1] "seed 60732 for j=28 out of 250 (i.e. j=4528 in [4501;4750], as job id is i=19)"
[1] "seed 43806 for j=29 out of 250 (i.e. j=4529 in [4501;4750], as job id is i=19)"
[1] "seed 59477 for j=30 out of 250 (i.e. j=4530 in [4501;4750], as job id is i=19)"
[1] "seed 26589 for j=31 out of 250 (i.e. j=4531 in [4501;4750], as job id is i=19)"
[1] "seed 39534 for j=32 out of 250 (i.e. j=4532 in [4501;4750], as job id is i=19)"
[1] "seed 76301 for j=33 out of 250 (i.e. j=4533 in [4501;4750], as job id is i=19)"
[1] "seed 42857 for j=34 out of 250 (i.e. j=4534 in [4501;4750], as job id is i=19)"
[1] "seed 23063 for j=35 out of 250 (i.e. j=4535 in [4501;4750], as job id is i=19)"
[1] "seed 22556 for j=36 out of 250 (i.e. j=4536 in [4501;4750], as job id is i=19)"
[1] "seed 16684 for j=37 out of 250 (i.e. j=4537 in [4501;4750], as job id is i=19)"
[1] "seed 35506 for j=38 out of 250 (i.e. j=4538 in [4501;4750], as job id is i=19)"
[1] "seed 34071 for j=39 out of 250 (i.e. j=4539 in [4501;4750], as job id is i=19)"
[1] "seed 33931 for j=40 out of 250 (i.e. j=4540 in [4501;4750], as job id is i=19)"
[1] "seed 46043 for j=41 out of 250 (i.e. j=4541 in [4501;4750], as job id is i=19)"
[1] "seed 69339 for j=42 out of 250 (i.e. j=4542 in [4501;4750], as job id is i=19)"
[1] "seed 46037 for j=43 out of 250 (i.e. j=4543 in [4501;4750], as job id is i=19)"
[1] "seed 80491 for j=44 out of 250 (i.e. j=4544 in [4501;4750], as job id is i=19)"
[1] "seed 90228 for j=45 out of 250 (i.e. j=4545 in [4501;4750], as job id is i=19)"
[1] "seed 81450 for j=46 out of 250 (i.e. j=4546 in [4501;4750], as job id is i=19)"
[1] "seed 7256 for j=47 out of 250 (i.e. j=4547 in [4501;4750], as job id is i=19)"
[1] "seed 41412 for j=48 out of 250 (i.e. j=4548 in [4501;4750], as job id is i=19)"
[1] "seed 29546 for j=49 out of 250 (i.e. j=4549 in [4501;4750], as job id is i=19)"
[1] "seed 3760 for j=50 out of 250 (i.e. j=4550 in [4501;4750], as job id is i=19)"
[1] "seed 24886 for j=51 out of 250 (i.e. j=4551 in [4501;4750], as job id is i=19)"
[1] "seed 4645 for j=52 out of 250 (i.e. j=4552 in [4501;4750], as job id is i=19)"
[1] "seed 64977 for j=53 out of 250 (i.e. j=4553 in [4501;4750], as job id is i=19)"
[1] "seed 61497 for j=54 out of 250 (i.e. j=4554 in [4501;4750], as job id is i=19)"
[1] "seed 69215 for j=55 out of 250 (i.e. j=4555 in [4501;4750], as job id is i=19)"
[1] "seed 28699 for j=56 out of 250 (i.e. j=4556 in [4501;4750], as job id is i=19)"
[1] "seed 5090 for j=57 out of 250 (i.e. j=4557 in [4501;4750], as job id is i=19)"
[1] "seed 27063 for j=58 out of 250 (i.e. j=4558 in [4501;4750], as job id is i=19)"
[1] "seed 85473 for j=59 out of 250 (i.e. j=4559 in [4501;4750], as job id is i=19)"
[1] "seed 28382 for j=60 out of 250 (i.e. j=4560 in [4501;4750], as job id is i=19)"
[1] "seed 40761 for j=61 out of 250 (i.e. j=4561 in [4501;4750], as job id is i=19)"
[1] "seed 93216 for j=62 out of 250 (i.e. j=4562 in [4501;4750], as job id is i=19)"
[1] "seed 97458 for j=63 out of 250 (i.e. j=4563 in [4501;4750], as job id is i=19)"
[1] "seed 70132 for j=64 out of 250 (i.e. j=4564 in [4501;4750], as job id is i=19)"
[1] "seed 72327 for j=65 out of 250 (i.e. j=4565 in [4501;4750], as job id is i=19)"
[1] "seed 80284 for j=66 out of 250 (i.e. j=4566 in [4501;4750], as job id is i=19)"
[1] "seed 32101 for j=67 out of 250 (i.e. j=4567 in [4501;4750], as job id is i=19)"
[1] "seed 48647 for j=68 out of 250 (i.e. j=4568 in [4501;4750], as job id is i=19)"
[1] "seed 12074 for j=69 out of 250 (i.e. j=4569 in [4501;4750], as job id is i=19)"
[1] "seed 15631 for j=70 out of 250 (i.e. j=4570 in [4501;4750], as job id is i=19)"
[1] "seed 91927 for j=71 out of 250 (i.e. j=4571 in [4501;4750], as job id is i=19)"
[1] "seed 13948 for j=72 out of 250 (i.e. j=4572 in [4501;4750], as job id is i=19)"
[1] "seed 94720 for j=73 out of 250 (i.e. j=4573 in [4501;4750], as job id is i=19)"
[1] "seed 45825 for j=74 out of 250 (i.e. j=4574 in [4501;4750], as job id is i=19)"
[1] "seed 13959 for j=75 out of 250 (i.e. j=4575 in [4501;4750], as job id is i=19)"
[1] "seed 33361 for j=76 out of 250 (i.e. j=4576 in [4501;4750], as job id is i=19)"
[1] "seed 65727 for j=77 out of 250 (i.e. j=4577 in [4501;4750], as job id is i=19)"
[1] "seed 12737 for j=78 out of 250 (i.e. j=4578 in [4501;4750], as job id is i=19)"
[1] "seed 35968 for j=79 out of 250 (i.e. j=4579 in [4501;4750], as job id is i=19)"
[1] "seed 8235 for j=80 out of 250 (i.e. j=4580 in [4501;4750], as job id is i=19)"
[1] "seed 42927 for j=81 out of 250 (i.e. j=4581 in [4501;4750], as job id is i=19)"
[1] "seed 40672 for j=82 out of 250 (i.e. j=4582 in [4501;4750], as job id is i=19)"
[1] "seed 75404 for j=83 out of 250 (i.e. j=4583 in [4501;4750], as job id is i=19)"
[1] "seed 43175 for j=84 out of 250 (i.e. j=4584 in [4501;4750], as job id is i=19)"
[1] "seed 21729 for j=85 out of 250 (i.e. j=4585 in [4501;4750], as job id is i=19)"
[1] "seed 22208 for j=86 out of 250 (i.e. j=4586 in [4501;4750], as job id is i=19)"
[1] "seed 58894 for j=87 out of 250 (i.e. j=4587 in [4501;4750], as job id is i=19)"
[1] "seed 37253 for j=88 out of 250 (i.e. j=4588 in [4501;4750], as job id is i=19)"
[1] "seed 91204 for j=89 out of 250 (i.e. j=4589 in [4501;4750], as job id is i=19)"
[1] "seed 2517 for j=90 out of 250 (i.e. j=4590 in [4501;4750], as job id is i=19)"
[1] "seed 36180 for j=91 out of 250 (i.e. j=4591 in [4501;4750], as job id is i=19)"
[1] "seed 14637 for j=92 out of 250 (i.e. j=4592 in [4501;4750], as job id is i=19)"
[1] "seed 53057 for j=93 out of 250 (i.e. j=4593 in [4501;4750], as job id is i=19)"
[1] "seed 22163 for j=94 out of 250 (i.e. j=4594 in [4501;4750], as job id is i=19)"
[1] "seed 83175 for j=95 out of 250 (i.e. j=4595 in [4501;4750], as job id is i=19)"
[1] "seed 76185 for j=96 out of 250 (i.e. j=4596 in [4501;4750], as job id is i=19)"
[1] "seed 57492 for j=97 out of 250 (i.e. j=4597 in [4501;4750], as job id is i=19)"
[1] "seed 98250 for j=98 out of 250 (i.e. j=4598 in [4501;4750], as job id is i=19)"
[1] "seed 3909 for j=99 out of 250 (i.e. j=4599 in [4501;4750], as job id is i=19)"
[1] "seed 81904 for j=100 out of 250 (i.e. j=4600 in [4501;4750], as job id is i=19)"
[1] "seed 60937 for j=101 out of 250 (i.e. j=4601 in [4501;4750], as job id is i=19)"
[1] "seed 33957 for j=102 out of 250 (i.e. j=4602 in [4501;4750], as job id is i=19)"
[1] "seed 52050 for j=103 out of 250 (i.e. j=4603 in [4501;4750], as job id is i=19)"
[1] "seed 81224 for j=104 out of 250 (i.e. j=4604 in [4501;4750], as job id is i=19)"
[1] "seed 56332 for j=105 out of 250 (i.e. j=4605 in [4501;4750], as job id is i=19)"
[1] "seed 95000 for j=106 out of 250 (i.e. j=4606 in [4501;4750], as job id is i=19)"
[1] "seed 89183 for j=107 out of 250 (i.e. j=4607 in [4501;4750], as job id is i=19)"
[1] "seed 31605 for j=108 out of 250 (i.e. j=4608 in [4501;4750], as job id is i=19)"
[1] "seed 60860 for j=109 out of 250 (i.e. j=4609 in [4501;4750], as job id is i=19)"
[1] "seed 67667 for j=110 out of 250 (i.e. j=4610 in [4501;4750], as job id is i=19)"
[1] "seed 7761 for j=111 out of 250 (i.e. j=4611 in [4501;4750], as job id is i=19)"
[1] "seed 12413 for j=112 out of 250 (i.e. j=4612 in [4501;4750], as job id is i=19)"
[1] "seed 92649 for j=113 out of 250 (i.e. j=4613 in [4501;4750], as job id is i=19)"
[1] "seed 4844 for j=114 out of 250 (i.e. j=4614 in [4501;4750], as job id is i=19)"
[1] "seed 26240 for j=115 out of 250 (i.e. j=4615 in [4501;4750], as job id is i=19)"
[1] "seed 22719 for j=116 out of 250 (i.e. j=4616 in [4501;4750], as job id is i=19)"
[1] "seed 5923 for j=117 out of 250 (i.e. j=4617 in [4501;4750], as job id is i=19)"
[1] "seed 75550 for j=118 out of 250 (i.e. j=4618 in [4501;4750], as job id is i=19)"
[1] "seed 28672 for j=119 out of 250 (i.e. j=4619 in [4501;4750], as job id is i=19)"
[1] "seed 70049 for j=120 out of 250 (i.e. j=4620 in [4501;4750], as job id is i=19)"
[1] "seed 80883 for j=121 out of 250 (i.e. j=4621 in [4501;4750], as job id is i=19)"
[1] "seed 15845 for j=122 out of 250 (i.e. j=4622 in [4501;4750], as job id is i=19)"
[1] "seed 61937 for j=123 out of 250 (i.e. j=4623 in [4501;4750], as job id is i=19)"
[1] "seed 44822 for j=124 out of 250 (i.e. j=4624 in [4501;4750], as job id is i=19)"
[1] "seed 92115 for j=125 out of 250 (i.e. j=4625 in [4501;4750], as job id is i=19)"
[1] "seed 30149 for j=126 out of 250 (i.e. j=4626 in [4501;4750], as job id is i=19)"
[1] "seed 74266 for j=127 out of 250 (i.e. j=4627 in [4501;4750], as job id is i=19)"
[1] "seed 37054 for j=128 out of 250 (i.e. j=4628 in [4501;4750], as job id is i=19)"
[1] "seed 90083 for j=129 out of 250 (i.e. j=4629 in [4501;4750], as job id is i=19)"
[1] "seed 91455 for j=130 out of 250 (i.e. j=4630 in [4501;4750], as job id is i=19)"
[1] "seed 90554 for j=131 out of 250 (i.e. j=4631 in [4501;4750], as job id is i=19)"
[1] "seed 32342 for j=132 out of 250 (i.e. j=4632 in [4501;4750], as job id is i=19)"
[1] "seed 17187 for j=133 out of 250 (i.e. j=4633 in [4501;4750], as job id is i=19)"
[1] "seed 2816 for j=134 out of 250 (i.e. j=4634 in [4501;4750], as job id is i=19)"
[1] "seed 85663 for j=135 out of 250 (i.e. j=4635 in [4501;4750], as job id is i=19)"
[1] "seed 98254 for j=136 out of 250 (i.e. j=4636 in [4501;4750], as job id is i=19)"
[1] "seed 20156 for j=137 out of 250 (i.e. j=4637 in [4501;4750], as job id is i=19)"
[1] "seed 68326 for j=138 out of 250 (i.e. j=4638 in [4501;4750], as job id is i=19)"
[1] "seed 85467 for j=139 out of 250 (i.e. j=4639 in [4501;4750], as job id is i=19)"
[1] "seed 48845 for j=140 out of 250 (i.e. j=4640 in [4501;4750], as job id is i=19)"
[1] "seed 84244 for j=141 out of 250 (i.e. j=4641 in [4501;4750], as job id is i=19)"
[1] "seed 63262 for j=142 out of 250 (i.e. j=4642 in [4501;4750], as job id is i=19)"
[1] "seed 33333 for j=143 out of 250 (i.e. j=4643 in [4501;4750], as job id is i=19)"
Error in uniroot(function(x) { : 
  f() values at end points not of opposite sign
Calls: update ... update.delayedGSD -> updateBoundaries -> updateMethod1 -> uniroot
In addition: Warning messages:
1: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

2: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

3: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

4: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

5: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

6: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

Execution halted
