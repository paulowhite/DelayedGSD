
R version 4.1.2 (2021-11-01) -- "Bird Hippie"
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ### BATCH_simuMain.R --- 
> #----------------------------------------------------------------------
> ## Author: Paul Blanche
> ## Created: Mar  5 2021 (10:56) 
> ## Version: 
> ## Last-Updated: maj  6 2022 (10:22) 
> ##           By: Brice Ozenne
> ##     Update #: 512
> #----------------------------------------------------------------------
> ## 
> ### Commentary: 
> ## 
> ### Change Log:
> #----------------------------------------------------------------------
> ## 
> ### Code:
> 
> rm(list=ls())
>                                    # {{{ parameters
> ## * parameters
> name <- "ScenarioName" # To save the results
> method <- 1:2 # methods used to compute the boundaries
>                                         #---
> myseed <- 140786598
>                                         #--- to plan the trial ----
> NMC <- 250 # number of sequential simulations to run in parallel. Eg. with 250, then we can run 40 scripts in paralell to get N=10,000 runs in total.
> kMax <- 2  #max number of analyses (including final)
> alpha <- 0.025  #type I error (one sided)
> beta <- 0.2  #type II error
> informationRates <- c(0.5,1)  #planned  information rates
> rho_alpha <- 2  # rho parameter for alpha error spending function
> rho_beta <- 2  # rho parameter for beta error spending function
> ## deltaPower <- 0.75 # just to try another value when Id > Imax
> Id <- 0.55  #(expected) information rate at each decision analysis
> binding <- TRUE
>                                         #
>                                         #---- to generate data -----------
>                                         #
> block <- c(1,1,0,0) 
> allsd <- c(2.5,2.1,2.4) # sd, first from baseline measurement, then the two changes from baseline
> mean0 <- c(10,0,0) # mean placebo group (again, first is absolute value, then change from baseline)
> delta <- c(0,0.6,0.8) # treatment effect
> ar <- (0.86*2)*2 # orginial accrual rate from data from Corine is 0.86 per week, hence we multiply by 2 for by 14 days. As to low, we further multiply by 2
> cor011 <- -0.15 # ~ from data from Corine
> corij1 <- 0.68  # ~ from data from Corine
> cor0j1 <- -0.27  # ~ from data from Corine
> Miss11 <- 5/104 # miss both V1 and V2
> Miss12 <- 1/104 # miss V1 and but not V2
> Miss21 <- 6/104 # do not miss V1 and but miss V2
> Miss22 <- 92/104 # miss none
> PropForInterim <- 0.5 # Decide to have interim analysiz when PropForInterim % of all subjects have had the chance to have one follow-up measuement recorded in the data to be available for analysis.
> theDelta.t <- 1.50001 # time lag to process the data and make them ready to analyze after collecting them (unit is time between two follow-up visits)
> TimeFactor <- 14 ## number of days between two visits
>                                         #
>                                         #--- actually for both planing the trial  and generating data-----
>                                         #
>                                         #
> deltaPower <- abs(delta[3]) # effect (NOT Z-scale/unit, but outcome scale/unit!) that the study is powered for: should we choose ourselves or compute from other numbers above ???
> n <- ceiling(2*2*((allsd[3]/deltaPower)^2)*(qnorm(1-beta)-qnorm(alpha))^2) #104 with Corine's data # should we choose ourselves or compute from the above numbers ???
>                                         # inflate SS as required for interim
> 
> # {{{ Set seeds for parallel computing and reproducibility
> ## * Seed
> iter_sim <- as.numeric(Sys.getenv("SLURM_ARRAY_TASK_ID"))
> n.iter_sim <- as.numeric(Sys.getenv("SLURM_ARRAY_TASK_COUNT"))
> if(is.na(iter_sim)){iter_sim <- 2}
> if(is.na(n.iter_sim)){n.iter_sim <- 10}
> 
> set.seed(140786598)
> allseeds <- sample.int(n = 10*n.iter_sim*NMC, size = n.iter_sim*NMC, replace=FALSE) #x=1:(.Machine$integer.max) seems to be maximal possible
> # }}}
> 
> # {{{ set path to load and save and othe machine specific variables
> ## * path
> path <- "."
> path.res <- file.path(path,"Results","simuMain")
> if(dir.exists(path.res)==FALSE){
+     if(dir.exists(file.path(path,"Results"))==FALSE){
+     dir.create(file.path(path,"Results"))
+     }
+     dir.create(path.res)
+ }
> path.output <- file.path(path,"output","simuMain")
> if(dir.exists(path.output)==FALSE){
+     if(dir.exists(file.path(path,"output"))==FALSE){
+     dir.create(file.path(path,"output"))
+     }
+     dir.create(path.output)
+ }
> # }}}
> 
> 
> ## * libraries and functions
> library(DelayedGSD)
DelayedGSD version 0.0.2
> ## sourceDir <- function(path, trace = TRUE, ...) {
> ##     for (nm in list.files(path, pattern = "[.][RrSsQq]$")) {
> ##         if(trace) cat(nm,":")
> ##         source(file.path(path, nm), ...)
> ##         if(trace) cat("\n")
> ##     }
> ## }
> ## sourceDir(pathToLoad)
>     
> 
> ## * Compute inflation factor and sample size
> plannedB <- vector(mode = "list", length = 3)
> for(iMeth in method){ ## iMeth <- 1
+     plannedB[[iMeth]] <- CalcBoundaries(kMax=kMax,  
+                                         alpha=alpha, 
+                                         beta=beta,  
+                                         InfoR.i=informationRates,  
+                                         InfoR.d=c(Id,1),  
+                                         rho_alpha=rho_alpha,  
+                                         rho_beta=rho_beta,  
+                                         method=iMeth,  
+                                         cNotBelowFixedc=FALSE,
+                                         bindingFutility=binding,
+                                         delta=tail(delta,1))
+     ## summary(plannedB[[1]])
+     ## coef(plannedB[[iMeth]], type = "information")
+ }
Loading required namespace: gsDesign
Loading required package: mvtnorm
Loading required namespace: BB
> inflationFactor <- unlist(lapply(plannedB,function(iP){iP$planned$InflationFactor}))
> nGSD <- ceiling(n*inflationFactor)
> ##  plot(plannedB[[1]])
> 
> #
> # --- just to check---
> ## n
> ## InfoFixed <- ((qnorm(1-beta)-qnorm(alpha))/(deltaPower))^2
> ## InfoFixed
> ## n/(4*(allsd[3])^2)
> #---
> # }}}
> 
> 
> 
> 
> # {{{ technical details to loop
> RES <- NULL # initialize results to save
> allj <- ((iter_sim-1)*NMC + 1):(iter_sim*NMC) # indices of all iterations (replicates) for this job, accountng for the other jobs running in parallel
> # }}}
> 
> ## * Loop
> for(j in allj){ ## j <- 5 ## 5
+     startComp <- Sys.time()
+     myseedi <- allseeds[j]
+     # {{{ TRACE info (e.g. to check the Rout)
+     print(paste0("seed ",myseedi," for ","j=",which(j==allj)," out of ",NMC, " (i.e. j=",j," in [",(iter_sim-1)*NMC + 1,";",iter_sim*NMC,"], as job id is i=",iter_sim,")"))
+     # }}}
+     # {{{ Missing probabilities
+     MyMissProb <- matrix(c(Miss11,Miss12,Miss21,Miss22),ncol=2,nrow=2,byrow=TRUE) # to additionnally remove 1 more because some FASFL=N
+     colnames(MyMissProb) <- c("V2 missing","V2 not missing")
+     rownames(MyMissProb) <- c("V1 missing","V1 not missing")
+     # }}}
+ 
+                                         # {{{ generate data
+     ## ** simulate
+     res <- GenData(n=n, 
+                    N.fw=2,
+                    rand.block=block,
+                    allsd=allsd,
+                    mean0=mean0,
+                    delta=delta,
+                    ar=ar,
+                    cor.01.1=cor011,
+                    cor.ij.1=corij1,
+                    cor.0j.1=cor0j1,
+                    seed=myseedi,
+                    MissProb=MyMissProb,
+                    DigitsOutcome=2,
+                    TimeFactor=TimeFactor,
+                    DigitsTime=0
+                    )
+     d <- res$d
+     ## head(d,n=20)
+                                         # }}}
+                                         # {{{ reformat data like those of Corine
+     ## Make data long format
+     ## dd <- FormatAsCase(d)
+     ## head(dd)
+     ## summary(dd)
+                                         # }}}
+    
+                                         # {{{ make data available at interim
+                                         # Here we stop inclusion data collection for the interim analysis as soon as
+                                         # half of the participants have completed (or had the opportunity to complete) the follow-up 
+     thet <- d$t3[ceiling(n*PropForInterim)]
+     di <- SelectData(d,t=thet)
+     ## ddi <- FormatAsCase(di) # needed ????
+     ## head(d[d$id==52,])
+                                         # }}}
+     ## {{{ analyze data at at interim
+     ## ** interim
+     lmmI <- analyzeData(di, ddf = "nlme", data.decision = sum(d$t1 <= thet + theDelta.t*TimeFactor), getinfo = TRUE, trace = TRUE)
+     ## lmmI <- analyzeData(di, ddf = "nlme", getinfo = TRUE, trace = TRUE)
+ 
+     currentGSD <- vector(mode = "list", length = 3)
+     out.interim <- vector(mode = "list", length = 3)
+     for(iMeth in method){ ## iMeth <- 1
+ 
+         currentGSD[[iMeth]] <- update(plannedB[[iMeth]], delta = lmmI, trace = FALSE)
+ 
+         iConfint.interim <- confint(currentGSD[[iMeth]])
+         iInfo.interim <- coef(currentGSD[[iMeth]], type = "information")
+         iBoundary.interim <- coef(currentGSD[[iMeth]], type = "boundary")
+         iDecision.interim <- coef(currentGSD[[iMeth]], type = "decision")
+ 
+         out.interim[[iMeth]] <-  data.frame(statistic = iConfint.interim[1,"statistic"],
+                                             estimate_ML = iConfint.interim[1,"estimate"],
+                                             se_ML = iConfint.interim[1,"se"],
+                                             info = iInfo.interim[1,"Interim"],
+                                             infoPC = iInfo.interim[1,"Interim.pc"],
+                                             info.pred = iInfo.interim[1,"Decision"],
+                                             infoPC.pred = iInfo.interim[1,"Decision.pc"],
+                                             uk = iBoundary.interim[1,"Ebound"],
+                                             lk = iBoundary.interim[1,"Fbound"],
+                                             decision = iDecision.interim["decision","stage 1"],
+                                             reason = iDecision.interim["reason.interim","stage 1"])
+     }
+     ## currentGSD[[1]]
+     ## plot(currentGSD[[1]])
+ 
+     ## ** decision
+     dDecision <- d[which(d$t1 <= thet + theDelta.t*TimeFactor),]
+     lmmD <- analyzeData(dDecision, ddf = "nlme", getinfo = TRUE, trace = TRUE)
+     
+     out.decision <- vector(mode = "list", length = 3)
+     for(iMeth in method){ ## iMeth <- 1
+           
+         if(out.interim[[iMeth]]$decision == "stop"){
+             currentGSD[[iMeth]] <- update(currentGSD[[iMeth]], delta = lmmD, trace = FALSE)
+             ## plot(currentGSD[[iMeth]])
+ 
+             iConfint.decision <- confint(currentGSD[[iMeth]], method = c("ML","MUE"))
+             iInfo.decision <- coef(currentGSD[[iMeth]], type = "information")
+             iBoundary.decision <- coef(currentGSD[[iMeth]], type = "boundary")
+             iDecision.decision  <- coef(currentGSD[[iMeth]], type = "decision")
+ 
+             out.decision[[iMeth]] <- data.frame(statistic = iConfint.decision[1,"statistic"],
+                                                 p.value_ML = iConfint.decision[iConfint.decision$method == "ML","p.value"],
+                                                 lower_ML = iConfint.decision[iConfint.decision$method == "ML","lower"],
+                                                 upper_ML = iConfint.decision[iConfint.decision$method == "ML","upper"],
+                                                 estimate_ML = iConfint.decision[iConfint.decision$method == "ML","estimate"],
+                                                 p.value_MUE = iConfint.decision[iConfint.decision$method == "MUE","p.value"],
+                                                 lower_MUE = iConfint.decision[iConfint.decision$method == "MUE","lower"],
+                                                 upper_MUE = iConfint.decision[iConfint.decision$method == "MUE","upper"],
+                                                 estimate_MUE = iConfint.decision[iConfint.decision$method == "MUE","estimate"],
+                                                 info = iInfo.decision[1,"Interim"],
+                                                 infoPC = iInfo.decision[1,"Interim.pc"],
+                                                 ck = iBoundary.decision[1,"Cbound"],
+                                                 decision = unname(iDecision.decision["decision","stage 2"])
+                                                 )
+ 
+         }else{
+             ## update information
+             currentGSD[[iMeth]] <- update(currentGSD[[iMeth]], delta = lmmD, k = 1, type.k = "decision", trace = FALSE)
+ 
+             iInfo.decision <- coef(currentGSD[[iMeth]], type = "information")
+             iBoundary.decision <- coef(currentGSD[[iMeth]], type = "boundary")
+ 
+             out.decision[[iMeth]] <- data.frame(statistic = NA,
+                                                 p.value_ML = NA,
+                                                 lower_ML = NA,
+                                                 upper_ML = NA,
+                                                 estimate_ML = NA,
+                                                 p.value_MUE = NA,
+                                                 lower_MUE = NA,
+                                                 upper_MUE = NA,
+                                                 estimate_MUE = NA,
+                                                 info = iInfo.decision[1,"Decision"],
+                                                 infoPC = iInfo.decision[1,"Decision.pc"],
+                                                 ck = iBoundary.decision[1,"Cbound"],
+                                                 decision = NA)
+         }
+     }
+                                         # }}}
+                                         # {{{ Analyze data at decision
+ 
+     ## ** finale
+     dFinal <- d
+     lmmF <- analyzeData(dFinal, ddf = "nlme", getinfo = TRUE, trace = TRUE)
+ 
+     out.final <- vector(mode = "list", length = 3)
+     for(iMeth in method){ ## iMeth <- 1
+         if(out.interim[[iMeth]]$decision == "stop"){
+             out.final[[iMeth]] <- data.frame(statistic = NA,
+                                              p.value_ML = NA,
+                                              lower_ML = NA,
+                                              upper_ML = NA,
+                                              estimate_ML = NA,
+                                              p.value_MUE = NA,
+                                              lower_MUE = NA,
+                                              upper_MUE = NA,
+                                              estimate_MUE = NA,
+                                              info = NA,
+                                              infoPC = NA,
+                                              ck = NA,
+                                              decision = NA)
+ 
+         }else{
+             currentGSD[[iMeth]] <- update(currentGSD[[iMeth]], delta = lmmF, trace = FALSE)
+ 
+             ## plot(test)
+             ## summary(test)
+             iConfint.final <- confint(currentGSD[[iMeth]], method = c("ML","MUE"))
+             iInfo.final <- coef(currentGSD[[iMeth]], type = "information")
+             iBoundary.final <- coef(currentGSD[[iMeth]], type = "boundary")
+             iDecision.final  <- coef(currentGSD[[iMeth]], type = "decision")
+ 
+             out.final[[iMeth]] <- data.frame(statistic = iConfint.final[1,"statistic"],
+                                              p.value_ML = iConfint.final[iConfint.final$method == "ML","p.value"],
+                                              lower_ML = iConfint.final[iConfint.final$method == "ML","lower"],
+                                              upper_ML = iConfint.final[iConfint.final$method == "ML","upper"],
+                                              estimate_ML = iConfint.final[iConfint.final$method == "ML","estimate"],
+                                              p.value_MUE = iConfint.final[iConfint.final$method == "MUE","p.value"],
+                                              lower_MUE = iConfint.final[iConfint.final$method == "MUE","lower"],
+                                              upper_MUE = iConfint.final[iConfint.final$method == "MUE","upper"],
+                                              estimate_MUE = iConfint.final[iConfint.final$method == "MUE","estimate"],
+                                              info = iInfo.final[1,"Interim"],
+                                              infoPC = iInfo.final[1,"Interim.pc"],
+                                              ck = iBoundary.final[1,"Cbound"],
+                                              decision = unname(coef(currentGSD[[iMeth]], type = "decision")["decision","stage 2"])
+                                              )
+         }
+     }
+                                         # }}}
+ 
+     stopComp <- Sys.time()
+                                         # {{{ Save results
+ 
+     outMerge <- do.call(rbind,lapply(method, function(iMeth){
+         iNames <- unique(c(names(out.interim[[iMeth]]),names(out.decision[[iMeth]]),names(out.final[[iMeth]])))
+         iMerge <- data.frame(matrix(NA, ncol = length(iNames)+3, nrow = 3, dimnames = list(NULL, c("method", "stage", "type", iNames))))
+         iMerge[1,c("method","stage","type",names(out.interim[[iMeth]]))] <- data.frame(method = iMeth, stage = 1, type = "interim", out.interim[[iMeth]]) 
+         iMerge[2,c("method","stage","type",names(out.decision[[iMeth]]))] <- data.frame(method = iMeth, stage = 1, type = "decision", out.decision[[iMeth]]) 
+         iMerge[3,c("method","stage","type",names(out.final[[iMeth]]))] <- data.frame(method = iMeth, stage = 2, type = "final", out.final[[iMeth]])
+         return(iMerge)
+     }))
+ 
+     ## outMerge[outMerge$method==3,]
+ 
+     out <- cbind(
+         ## results
+         outMerge,
+         ## simulation details
+         time.interim = thet,
+         seed=myseedi,             
+         nX1.interim = sum(!is.na(di$X1)),
+         nX2.interim = sum(!is.na(di$X2)),
+         nX3.interim = sum(!is.na(di$X3)),
+         ## computation time
+         computation.time=as.double(round(difftime(stopComp,startComp,units="secs"),3))
+     )
+     ## names(out) <- myColNames
+     RES <- rbind(RES,out)
+     save(RES,file=paste0(path.res,name,"(tempo)-",iter_sim,".rda"))
+                                         # }}}
+ }
[1] "seed 80886 for j=1 out of 250 (i.e. j=5001 in [5001;5250], as job id is i=21)"
Loading required namespace: nlme
[1] "seed 95588 for j=2 out of 250 (i.e. j=5002 in [5001;5250], as job id is i=21)"
[1] "seed 50677 for j=3 out of 250 (i.e. j=5003 in [5001;5250], as job id is i=21)"
[1] "seed 75179 for j=4 out of 250 (i.e. j=5004 in [5001;5250], as job id is i=21)"
[1] "seed 79222 for j=5 out of 250 (i.e. j=5005 in [5001;5250], as job id is i=21)"
[1] "seed 26923 for j=6 out of 250 (i.e. j=5006 in [5001;5250], as job id is i=21)"
[1] "seed 70149 for j=7 out of 250 (i.e. j=5007 in [5001;5250], as job id is i=21)"
[1] "seed 135 for j=8 out of 250 (i.e. j=5008 in [5001;5250], as job id is i=21)"
[1] "seed 37254 for j=9 out of 250 (i.e. j=5009 in [5001;5250], as job id is i=21)"
[1] "seed 46991 for j=10 out of 250 (i.e. j=5010 in [5001;5250], as job id is i=21)"
[1] "seed 90700 for j=11 out of 250 (i.e. j=5011 in [5001;5250], as job id is i=21)"
[1] "seed 56660 for j=12 out of 250 (i.e. j=5012 in [5001;5250], as job id is i=21)"
[1] "seed 58075 for j=13 out of 250 (i.e. j=5013 in [5001;5250], as job id is i=21)"
[1] "seed 87497 for j=14 out of 250 (i.e. j=5014 in [5001;5250], as job id is i=21)"
[1] "seed 14403 for j=15 out of 250 (i.e. j=5015 in [5001;5250], as job id is i=21)"
[1] "seed 77232 for j=16 out of 250 (i.e. j=5016 in [5001;5250], as job id is i=21)"
[1] "seed 74400 for j=17 out of 250 (i.e. j=5017 in [5001;5250], as job id is i=21)"
[1] "seed 53561 for j=18 out of 250 (i.e. j=5018 in [5001;5250], as job id is i=21)"
[1] "seed 77404 for j=19 out of 250 (i.e. j=5019 in [5001;5250], as job id is i=21)"
[1] "seed 41681 for j=20 out of 250 (i.e. j=5020 in [5001;5250], as job id is i=21)"
[1] "seed 88627 for j=21 out of 250 (i.e. j=5021 in [5001;5250], as job id is i=21)"
[1] "seed 71068 for j=22 out of 250 (i.e. j=5022 in [5001;5250], as job id is i=21)"
[1] "seed 87728 for j=23 out of 250 (i.e. j=5023 in [5001;5250], as job id is i=21)"
[1] "seed 52688 for j=24 out of 250 (i.e. j=5024 in [5001;5250], as job id is i=21)"
[1] "seed 74910 for j=25 out of 250 (i.e. j=5025 in [5001;5250], as job id is i=21)"
[1] "seed 41674 for j=26 out of 250 (i.e. j=5026 in [5001;5250], as job id is i=21)"
[1] "seed 51115 for j=27 out of 250 (i.e. j=5027 in [5001;5250], as job id is i=21)"
[1] "seed 86115 for j=28 out of 250 (i.e. j=5028 in [5001;5250], as job id is i=21)"
[1] "seed 82632 for j=29 out of 250 (i.e. j=5029 in [5001;5250], as job id is i=21)"
[1] "seed 96289 for j=30 out of 250 (i.e. j=5030 in [5001;5250], as job id is i=21)"
[1] "seed 42802 for j=31 out of 250 (i.e. j=5031 in [5001;5250], as job id is i=21)"
[1] "seed 55802 for j=32 out of 250 (i.e. j=5032 in [5001;5250], as job id is i=21)"
[1] "seed 58315 for j=33 out of 250 (i.e. j=5033 in [5001;5250], as job id is i=21)"
[1] "seed 92467 for j=34 out of 250 (i.e. j=5034 in [5001;5250], as job id is i=21)"
[1] "seed 59154 for j=35 out of 250 (i.e. j=5035 in [5001;5250], as job id is i=21)"
[1] "seed 10589 for j=36 out of 250 (i.e. j=5036 in [5001;5250], as job id is i=21)"
[1] "seed 72843 for j=37 out of 250 (i.e. j=5037 in [5001;5250], as job id is i=21)"
[1] "seed 68008 for j=38 out of 250 (i.e. j=5038 in [5001;5250], as job id is i=21)"
[1] "seed 6710 for j=39 out of 250 (i.e. j=5039 in [5001;5250], as job id is i=21)"
[1] "seed 76795 for j=40 out of 250 (i.e. j=5040 in [5001;5250], as job id is i=21)"
[1] "seed 74842 for j=41 out of 250 (i.e. j=5041 in [5001;5250], as job id is i=21)"
[1] "seed 12434 for j=42 out of 250 (i.e. j=5042 in [5001;5250], as job id is i=21)"
[1] "seed 71461 for j=43 out of 250 (i.e. j=5043 in [5001;5250], as job id is i=21)"
[1] "seed 34249 for j=44 out of 250 (i.e. j=5044 in [5001;5250], as job id is i=21)"
[1] "seed 54240 for j=45 out of 250 (i.e. j=5045 in [5001;5250], as job id is i=21)"
[1] "seed 78074 for j=46 out of 250 (i.e. j=5046 in [5001;5250], as job id is i=21)"
[1] "seed 84597 for j=47 out of 250 (i.e. j=5047 in [5001;5250], as job id is i=21)"
[1] "seed 76730 for j=48 out of 250 (i.e. j=5048 in [5001;5250], as job id is i=21)"
[1] "seed 76022 for j=49 out of 250 (i.e. j=5049 in [5001;5250], as job id is i=21)"
[1] "seed 47867 for j=50 out of 250 (i.e. j=5050 in [5001;5250], as job id is i=21)"
[1] "seed 59861 for j=51 out of 250 (i.e. j=5051 in [5001;5250], as job id is i=21)"
[1] "seed 16285 for j=52 out of 250 (i.e. j=5052 in [5001;5250], as job id is i=21)"
[1] "seed 79695 for j=53 out of 250 (i.e. j=5053 in [5001;5250], as job id is i=21)"
[1] "seed 77461 for j=54 out of 250 (i.e. j=5054 in [5001;5250], as job id is i=21)"
[1] "seed 29379 for j=55 out of 250 (i.e. j=5055 in [5001;5250], as job id is i=21)"
[1] "seed 91426 for j=56 out of 250 (i.e. j=5056 in [5001;5250], as job id is i=21)"
[1] "seed 64704 for j=57 out of 250 (i.e. j=5057 in [5001;5250], as job id is i=21)"
[1] "seed 7141 for j=58 out of 250 (i.e. j=5058 in [5001;5250], as job id is i=21)"
[1] "seed 4142 for j=59 out of 250 (i.e. j=5059 in [5001;5250], as job id is i=21)"
[1] "seed 15932 for j=60 out of 250 (i.e. j=5060 in [5001;5250], as job id is i=21)"
[1] "seed 92871 for j=61 out of 250 (i.e. j=5061 in [5001;5250], as job id is i=21)"
[1] "seed 99443 for j=62 out of 250 (i.e. j=5062 in [5001;5250], as job id is i=21)"
[1] "seed 12763 for j=63 out of 250 (i.e. j=5063 in [5001;5250], as job id is i=21)"
[1] "seed 68717 for j=64 out of 250 (i.e. j=5064 in [5001;5250], as job id is i=21)"
[1] "seed 93269 for j=65 out of 250 (i.e. j=5065 in [5001;5250], as job id is i=21)"
[1] "seed 92586 for j=66 out of 250 (i.e. j=5066 in [5001;5250], as job id is i=21)"
[1] "seed 22521 for j=67 out of 250 (i.e. j=5067 in [5001;5250], as job id is i=21)"
[1] "seed 1836 for j=68 out of 250 (i.e. j=5068 in [5001;5250], as job id is i=21)"
[1] "seed 1700 for j=69 out of 250 (i.e. j=5069 in [5001;5250], as job id is i=21)"
[1] "seed 56307 for j=70 out of 250 (i.e. j=5070 in [5001;5250], as job id is i=21)"
[1] "seed 11426 for j=71 out of 250 (i.e. j=5071 in [5001;5250], as job id is i=21)"
[1] "seed 29566 for j=72 out of 250 (i.e. j=5072 in [5001;5250], as job id is i=21)"
[1] "seed 56607 for j=73 out of 250 (i.e. j=5073 in [5001;5250], as job id is i=21)"
[1] "seed 66714 for j=74 out of 250 (i.e. j=5074 in [5001;5250], as job id is i=21)"
[1] "seed 79036 for j=75 out of 250 (i.e. j=5075 in [5001;5250], as job id is i=21)"
[1] "seed 7218 for j=76 out of 250 (i.e. j=5076 in [5001;5250], as job id is i=21)"
[1] "seed 13457 for j=77 out of 250 (i.e. j=5077 in [5001;5250], as job id is i=21)"
[1] "seed 65762 for j=78 out of 250 (i.e. j=5078 in [5001;5250], as job id is i=21)"
[1] "seed 43312 for j=79 out of 250 (i.e. j=5079 in [5001;5250], as job id is i=21)"
[1] "seed 58641 for j=80 out of 250 (i.e. j=5080 in [5001;5250], as job id is i=21)"
[1] "seed 5629 for j=81 out of 250 (i.e. j=5081 in [5001;5250], as job id is i=21)"
[1] "seed 4863 for j=82 out of 250 (i.e. j=5082 in [5001;5250], as job id is i=21)"
[1] "seed 17935 for j=83 out of 250 (i.e. j=5083 in [5001;5250], as job id is i=21)"
[1] "seed 81730 for j=84 out of 250 (i.e. j=5084 in [5001;5250], as job id is i=21)"
[1] "seed 40025 for j=85 out of 250 (i.e. j=5085 in [5001;5250], as job id is i=21)"
[1] "seed 65627 for j=86 out of 250 (i.e. j=5086 in [5001;5250], as job id is i=21)"
[1] "seed 86587 for j=87 out of 250 (i.e. j=5087 in [5001;5250], as job id is i=21)"
[1] "seed 42315 for j=88 out of 250 (i.e. j=5088 in [5001;5250], as job id is i=21)"
[1] "seed 30823 for j=89 out of 250 (i.e. j=5089 in [5001;5250], as job id is i=21)"
[1] "seed 74591 for j=90 out of 250 (i.e. j=5090 in [5001;5250], as job id is i=21)"
[1] "seed 50441 for j=91 out of 250 (i.e. j=5091 in [5001;5250], as job id is i=21)"
[1] "seed 85731 for j=92 out of 250 (i.e. j=5092 in [5001;5250], as job id is i=21)"
[1] "seed 90327 for j=93 out of 250 (i.e. j=5093 in [5001;5250], as job id is i=21)"
[1] "seed 7672 for j=94 out of 250 (i.e. j=5094 in [5001;5250], as job id is i=21)"
[1] "seed 79591 for j=95 out of 250 (i.e. j=5095 in [5001;5250], as job id is i=21)"
[1] "seed 69916 for j=96 out of 250 (i.e. j=5096 in [5001;5250], as job id is i=21)"
[1] "seed 54465 for j=97 out of 250 (i.e. j=5097 in [5001;5250], as job id is i=21)"
[1] "seed 44303 for j=98 out of 250 (i.e. j=5098 in [5001;5250], as job id is i=21)"
[1] "seed 98055 for j=99 out of 250 (i.e. j=5099 in [5001;5250], as job id is i=21)"
Error in uniroot(function(x) { : 
  f() values at end points not of opposite sign
Calls: update ... update.delayedGSD -> updateBoundaries -> updateMethod1 -> uniroot
In addition: Warning messages:
1: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

2: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

3: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

4: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

5: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

6: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

7: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

8: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

9: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

10: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

Execution halted
