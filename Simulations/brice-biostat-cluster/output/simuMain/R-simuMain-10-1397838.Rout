
R version 4.1.2 (2021-11-01) -- "Bird Hippie"
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ### BATCH_simuMain.R --- 
> #----------------------------------------------------------------------
> ## Author: Paul Blanche
> ## Created: Mar  5 2021 (10:56) 
> ## Version: 
> ## Last-Updated: maj  6 2022 (10:22) 
> ##           By: Brice Ozenne
> ##     Update #: 512
> #----------------------------------------------------------------------
> ## 
> ### Commentary: 
> ## 
> ### Change Log:
> #----------------------------------------------------------------------
> ## 
> ### Code:
> 
> rm(list=ls())
>                                    # {{{ parameters
> ## * parameters
> name <- "ScenarioName" # To save the results
> method <- 1:2 # methods used to compute the boundaries
>                                         #---
> myseed <- 140786598
>                                         #--- to plan the trial ----
> NMC <- 250 # number of sequential simulations to run in parallel. Eg. with 250, then we can run 40 scripts in paralell to get N=10,000 runs in total.
> kMax <- 2  #max number of analyses (including final)
> alpha <- 0.025  #type I error (one sided)
> beta <- 0.2  #type II error
> informationRates <- c(0.5,1)  #planned  information rates
> rho_alpha <- 2  # rho parameter for alpha error spending function
> rho_beta <- 2  # rho parameter for beta error spending function
> ## deltaPower <- 0.75 # just to try another value when Id > Imax
> Id <- 0.55  #(expected) information rate at each decision analysis
> binding <- TRUE
>                                         #
>                                         #---- to generate data -----------
>                                         #
> block <- c(1,1,0,0) 
> allsd <- c(2.5,2.1,2.4) # sd, first from baseline measurement, then the two changes from baseline
> mean0 <- c(10,0,0) # mean placebo group (again, first is absolute value, then change from baseline)
> delta <- c(0,0.6,0.8) # treatment effect
> ar <- (0.86*2)*2 # orginial accrual rate from data from Corine is 0.86 per week, hence we multiply by 2 for by 14 days. As to low, we further multiply by 2
> cor011 <- -0.15 # ~ from data from Corine
> corij1 <- 0.68  # ~ from data from Corine
> cor0j1 <- -0.27  # ~ from data from Corine
> Miss11 <- 5/104 # miss both V1 and V2
> Miss12 <- 1/104 # miss V1 and but not V2
> Miss21 <- 6/104 # do not miss V1 and but miss V2
> Miss22 <- 92/104 # miss none
> PropForInterim <- 0.5 # Decide to have interim analysiz when PropForInterim % of all subjects have had the chance to have one follow-up measuement recorded in the data to be available for analysis.
> theDelta.t <- 1.50001 # time lag to process the data and make them ready to analyze after collecting them (unit is time between two follow-up visits)
> TimeFactor <- 14 ## number of days between two visits
>                                         #
>                                         #--- actually for both planing the trial  and generating data-----
>                                         #
>                                         #
> deltaPower <- abs(delta[3]) # effect (NOT Z-scale/unit, but outcome scale/unit!) that the study is powered for: should we choose ourselves or compute from other numbers above ???
> n <- ceiling(2*2*((allsd[3]/deltaPower)^2)*(qnorm(1-beta)-qnorm(alpha))^2) #104 with Corine's data # should we choose ourselves or compute from the above numbers ???
>                                         # inflate SS as required for interim
> 
> # {{{ Set seeds for parallel computing and reproducibility
> ## * Seed
> iter_sim <- as.numeric(Sys.getenv("SLURM_ARRAY_TASK_ID"))
> n.iter_sim <- as.numeric(Sys.getenv("SLURM_ARRAY_TASK_COUNT"))
> if(is.na(iter_sim)){iter_sim <- 2}
> if(is.na(n.iter_sim)){n.iter_sim <- 10}
> 
> set.seed(140786598)
> allseeds <- sample.int(n = 10*n.iter_sim*NMC, size = n.iter_sim*NMC, replace=FALSE) #x=1:(.Machine$integer.max) seems to be maximal possible
> # }}}
> 
> # {{{ set path to load and save and othe machine specific variables
> ## * path
> path <- "."
> path.res <- file.path(path,"Results","simuMain")
> if(dir.exists(path.res)==FALSE){
+     if(dir.exists(file.path(path,"Results"))==FALSE){
+     dir.create(file.path(path,"Results"))
+     }
+     dir.create(path.res)
+ }
> path.output <- file.path(path,"output","simuMain")
> if(dir.exists(path.output)==FALSE){
+     if(dir.exists(file.path(path,"output"))==FALSE){
+     dir.create(file.path(path,"output"))
+     }
+     dir.create(path.output)
+ }
> # }}}
> 
> 
> ## * libraries and functions
> library(DelayedGSD)
DelayedGSD version 0.0.2
> ## sourceDir <- function(path, trace = TRUE, ...) {
> ##     for (nm in list.files(path, pattern = "[.][RrSsQq]$")) {
> ##         if(trace) cat(nm,":")
> ##         source(file.path(path, nm), ...)
> ##         if(trace) cat("\n")
> ##     }
> ## }
> ## sourceDir(pathToLoad)
>     
> 
> ## * Compute inflation factor and sample size
> plannedB <- vector(mode = "list", length = 3)
> for(iMeth in method){ ## iMeth <- 1
+     plannedB[[iMeth]] <- CalcBoundaries(kMax=kMax,  
+                                         alpha=alpha, 
+                                         beta=beta,  
+                                         InfoR.i=informationRates,  
+                                         InfoR.d=c(Id,1),  
+                                         rho_alpha=rho_alpha,  
+                                         rho_beta=rho_beta,  
+                                         method=iMeth,  
+                                         cNotBelowFixedc=FALSE,
+                                         bindingFutility=binding,
+                                         delta=tail(delta,1))
+     ## summary(plannedB[[1]])
+     ## coef(plannedB[[iMeth]], type = "information")
+ }
Loading required namespace: gsDesign
Loading required package: mvtnorm
Loading required namespace: BB
> inflationFactor <- unlist(lapply(plannedB,function(iP){iP$planned$InflationFactor}))
> nGSD <- ceiling(n*inflationFactor)
> ##  plot(plannedB[[1]])
> 
> #
> # --- just to check---
> ## n
> ## InfoFixed <- ((qnorm(1-beta)-qnorm(alpha))/(deltaPower))^2
> ## InfoFixed
> ## n/(4*(allsd[3])^2)
> #---
> # }}}
> 
> 
> 
> 
> # {{{ technical details to loop
> RES <- NULL # initialize results to save
> allj <- ((iter_sim-1)*NMC + 1):(iter_sim*NMC) # indices of all iterations (replicates) for this job, accountng for the other jobs running in parallel
> # }}}
> 
> ## * Loop
> for(j in allj){ ## j <- 5 ## 5
+     startComp <- Sys.time()
+     myseedi <- allseeds[j]
+     # {{{ TRACE info (e.g. to check the Rout)
+     print(paste0("seed ",myseedi," for ","j=",which(j==allj)," out of ",NMC, " (i.e. j=",j," in [",(iter_sim-1)*NMC + 1,";",iter_sim*NMC,"], as job id is i=",iter_sim,")"))
+     # }}}
+     # {{{ Missing probabilities
+     MyMissProb <- matrix(c(Miss11,Miss12,Miss21,Miss22),ncol=2,nrow=2,byrow=TRUE) # to additionnally remove 1 more because some FASFL=N
+     colnames(MyMissProb) <- c("V2 missing","V2 not missing")
+     rownames(MyMissProb) <- c("V1 missing","V1 not missing")
+     # }}}
+ 
+                                         # {{{ generate data
+     ## ** simulate
+     res <- GenData(n=n, 
+                    N.fw=2,
+                    rand.block=block,
+                    allsd=allsd,
+                    mean0=mean0,
+                    delta=delta,
+                    ar=ar,
+                    cor.01.1=cor011,
+                    cor.ij.1=corij1,
+                    cor.0j.1=cor0j1,
+                    seed=myseedi,
+                    MissProb=MyMissProb,
+                    DigitsOutcome=2,
+                    TimeFactor=TimeFactor,
+                    DigitsTime=0
+                    )
+     d <- res$d
+     ## head(d,n=20)
+                                         # }}}
+                                         # {{{ reformat data like those of Corine
+     ## Make data long format
+     ## dd <- FormatAsCase(d)
+     ## head(dd)
+     ## summary(dd)
+                                         # }}}
+    
+                                         # {{{ make data available at interim
+                                         # Here we stop inclusion data collection for the interim analysis as soon as
+                                         # half of the participants have completed (or had the opportunity to complete) the follow-up 
+     thet <- d$t3[ceiling(n*PropForInterim)]
+     di <- SelectData(d,t=thet)
+     ## ddi <- FormatAsCase(di) # needed ????
+     ## head(d[d$id==52,])
+                                         # }}}
+     ## {{{ analyze data at at interim
+     ## ** interim
+     lmmI <- analyzeData(di, ddf = "nlme", data.decision = sum(d$t1 <= thet + theDelta.t*TimeFactor), getinfo = TRUE, trace = TRUE)
+     ## lmmI <- analyzeData(di, ddf = "nlme", getinfo = TRUE, trace = TRUE)
+ 
+     currentGSD <- vector(mode = "list", length = 3)
+     out.interim <- vector(mode = "list", length = 3)
+     for(iMeth in method){ ## iMeth <- 1
+ 
+         currentGSD[[iMeth]] <- update(plannedB[[iMeth]], delta = lmmI, trace = FALSE)
+ 
+         iConfint.interim <- confint(currentGSD[[iMeth]])
+         iInfo.interim <- coef(currentGSD[[iMeth]], type = "information")
+         iBoundary.interim <- coef(currentGSD[[iMeth]], type = "boundary")
+         iDecision.interim <- coef(currentGSD[[iMeth]], type = "decision")
+ 
+         out.interim[[iMeth]] <-  data.frame(statistic = iConfint.interim[1,"statistic"],
+                                             estimate_ML = iConfint.interim[1,"estimate"],
+                                             se_ML = iConfint.interim[1,"se"],
+                                             info = iInfo.interim[1,"Interim"],
+                                             infoPC = iInfo.interim[1,"Interim.pc"],
+                                             info.pred = iInfo.interim[1,"Decision"],
+                                             infoPC.pred = iInfo.interim[1,"Decision.pc"],
+                                             uk = iBoundary.interim[1,"Ebound"],
+                                             lk = iBoundary.interim[1,"Fbound"],
+                                             decision = iDecision.interim["decision","stage 1"],
+                                             reason = iDecision.interim["reason.interim","stage 1"])
+     }
+     ## currentGSD[[1]]
+     ## plot(currentGSD[[1]])
+ 
+     ## ** decision
+     dDecision <- d[which(d$t1 <= thet + theDelta.t*TimeFactor),]
+     lmmD <- analyzeData(dDecision, ddf = "nlme", getinfo = TRUE, trace = TRUE)
+     
+     out.decision <- vector(mode = "list", length = 3)
+     for(iMeth in method){ ## iMeth <- 1
+           
+         if(out.interim[[iMeth]]$decision == "stop"){
+             currentGSD[[iMeth]] <- update(currentGSD[[iMeth]], delta = lmmD, trace = FALSE)
+             ## plot(currentGSD[[iMeth]])
+ 
+             iConfint.decision <- confint(currentGSD[[iMeth]], method = c("ML","MUE"))
+             iInfo.decision <- coef(currentGSD[[iMeth]], type = "information")
+             iBoundary.decision <- coef(currentGSD[[iMeth]], type = "boundary")
+             iDecision.decision  <- coef(currentGSD[[iMeth]], type = "decision")
+ 
+             out.decision[[iMeth]] <- data.frame(statistic = iConfint.decision[1,"statistic"],
+                                                 p.value_ML = iConfint.decision[iConfint.decision$method == "ML","p.value"],
+                                                 lower_ML = iConfint.decision[iConfint.decision$method == "ML","lower"],
+                                                 upper_ML = iConfint.decision[iConfint.decision$method == "ML","upper"],
+                                                 estimate_ML = iConfint.decision[iConfint.decision$method == "ML","estimate"],
+                                                 p.value_MUE = iConfint.decision[iConfint.decision$method == "MUE","p.value"],
+                                                 lower_MUE = iConfint.decision[iConfint.decision$method == "MUE","lower"],
+                                                 upper_MUE = iConfint.decision[iConfint.decision$method == "MUE","upper"],
+                                                 estimate_MUE = iConfint.decision[iConfint.decision$method == "MUE","estimate"],
+                                                 info = iInfo.decision[1,"Interim"],
+                                                 infoPC = iInfo.decision[1,"Interim.pc"],
+                                                 ck = iBoundary.decision[1,"Cbound"],
+                                                 decision = unname(iDecision.decision["decision","stage 2"])
+                                                 )
+ 
+         }else{
+             ## update information
+             currentGSD[[iMeth]] <- update(currentGSD[[iMeth]], delta = lmmD, k = 1, type.k = "decision", trace = FALSE)
+ 
+             iInfo.decision <- coef(currentGSD[[iMeth]], type = "information")
+             iBoundary.decision <- coef(currentGSD[[iMeth]], type = "boundary")
+ 
+             out.decision[[iMeth]] <- data.frame(statistic = NA,
+                                                 p.value_ML = NA,
+                                                 lower_ML = NA,
+                                                 upper_ML = NA,
+                                                 estimate_ML = NA,
+                                                 p.value_MUE = NA,
+                                                 lower_MUE = NA,
+                                                 upper_MUE = NA,
+                                                 estimate_MUE = NA,
+                                                 info = iInfo.decision[1,"Decision"],
+                                                 infoPC = iInfo.decision[1,"Decision.pc"],
+                                                 ck = iBoundary.decision[1,"Cbound"],
+                                                 decision = NA)
+         }
+     }
+                                         # }}}
+                                         # {{{ Analyze data at decision
+ 
+     ## ** finale
+     dFinal <- d
+     lmmF <- analyzeData(dFinal, ddf = "nlme", getinfo = TRUE, trace = TRUE)
+ 
+     out.final <- vector(mode = "list", length = 3)
+     for(iMeth in method){ ## iMeth <- 1
+         if(out.interim[[iMeth]]$decision == "stop"){
+             out.final[[iMeth]] <- data.frame(statistic = NA,
+                                              p.value_ML = NA,
+                                              lower_ML = NA,
+                                              upper_ML = NA,
+                                              estimate_ML = NA,
+                                              p.value_MUE = NA,
+                                              lower_MUE = NA,
+                                              upper_MUE = NA,
+                                              estimate_MUE = NA,
+                                              info = NA,
+                                              infoPC = NA,
+                                              ck = NA,
+                                              decision = NA)
+ 
+         }else{
+             currentGSD[[iMeth]] <- update(currentGSD[[iMeth]], delta = lmmF, trace = FALSE)
+ 
+             ## plot(test)
+             ## summary(test)
+             iConfint.final <- confint(currentGSD[[iMeth]], method = c("ML","MUE"))
+             iInfo.final <- coef(currentGSD[[iMeth]], type = "information")
+             iBoundary.final <- coef(currentGSD[[iMeth]], type = "boundary")
+             iDecision.final  <- coef(currentGSD[[iMeth]], type = "decision")
+ 
+             out.final[[iMeth]] <- data.frame(statistic = iConfint.final[1,"statistic"],
+                                              p.value_ML = iConfint.final[iConfint.final$method == "ML","p.value"],
+                                              lower_ML = iConfint.final[iConfint.final$method == "ML","lower"],
+                                              upper_ML = iConfint.final[iConfint.final$method == "ML","upper"],
+                                              estimate_ML = iConfint.final[iConfint.final$method == "ML","estimate"],
+                                              p.value_MUE = iConfint.final[iConfint.final$method == "MUE","p.value"],
+                                              lower_MUE = iConfint.final[iConfint.final$method == "MUE","lower"],
+                                              upper_MUE = iConfint.final[iConfint.final$method == "MUE","upper"],
+                                              estimate_MUE = iConfint.final[iConfint.final$method == "MUE","estimate"],
+                                              info = iInfo.final[1,"Interim"],
+                                              infoPC = iInfo.final[1,"Interim.pc"],
+                                              ck = iBoundary.final[1,"Cbound"],
+                                              decision = unname(coef(currentGSD[[iMeth]], type = "decision")["decision","stage 2"])
+                                              )
+         }
+     }
+                                         # }}}
+ 
+     stopComp <- Sys.time()
+                                         # {{{ Save results
+ 
+     outMerge <- do.call(rbind,lapply(method, function(iMeth){
+         iNames <- unique(c(names(out.interim[[iMeth]]),names(out.decision[[iMeth]]),names(out.final[[iMeth]])))
+         iMerge <- data.frame(matrix(NA, ncol = length(iNames)+3, nrow = 3, dimnames = list(NULL, c("method", "stage", "type", iNames))))
+         iMerge[1,c("method","stage","type",names(out.interim[[iMeth]]))] <- data.frame(method = iMeth, stage = 1, type = "interim", out.interim[[iMeth]]) 
+         iMerge[2,c("method","stage","type",names(out.decision[[iMeth]]))] <- data.frame(method = iMeth, stage = 1, type = "decision", out.decision[[iMeth]]) 
+         iMerge[3,c("method","stage","type",names(out.final[[iMeth]]))] <- data.frame(method = iMeth, stage = 2, type = "final", out.final[[iMeth]])
+         return(iMerge)
+     }))
+ 
+     ## outMerge[outMerge$method==3,]
+ 
+     out <- cbind(
+         ## results
+         outMerge,
+         ## simulation details
+         time.interim = thet,
+         seed=myseedi,             
+         nX1.interim = sum(!is.na(di$X1)),
+         nX2.interim = sum(!is.na(di$X2)),
+         nX3.interim = sum(!is.na(di$X3)),
+         ## computation time
+         computation.time=as.double(round(difftime(stopComp,startComp,units="secs"),3))
+     )
+     ## names(out) <- myColNames
+     RES <- rbind(RES,out)
+     save(RES,file=paste0(path.res,name,"(tempo)-",iter_sim,".rda"))
+                                         # }}}
+ }
[1] "seed 14854 for j=1 out of 250 (i.e. j=2251 in [2251;2500], as job id is i=10)"
Loading required namespace: nlme
[1] "seed 49790 for j=2 out of 250 (i.e. j=2252 in [2251;2500], as job id is i=10)"
[1] "seed 8889 for j=3 out of 250 (i.e. j=2253 in [2251;2500], as job id is i=10)"
[1] "seed 11969 for j=4 out of 250 (i.e. j=2254 in [2251;2500], as job id is i=10)"
[1] "seed 94291 for j=5 out of 250 (i.e. j=2255 in [2251;2500], as job id is i=10)"
[1] "seed 97881 for j=6 out of 250 (i.e. j=2256 in [2251;2500], as job id is i=10)"
[1] "seed 37241 for j=7 out of 250 (i.e. j=2257 in [2251;2500], as job id is i=10)"
[1] "seed 48252 for j=8 out of 250 (i.e. j=2258 in [2251;2500], as job id is i=10)"
[1] "seed 70753 for j=9 out of 250 (i.e. j=2259 in [2251;2500], as job id is i=10)"
[1] "seed 49620 for j=10 out of 250 (i.e. j=2260 in [2251;2500], as job id is i=10)"
[1] "seed 60473 for j=11 out of 250 (i.e. j=2261 in [2251;2500], as job id is i=10)"
[1] "seed 3729 for j=12 out of 250 (i.e. j=2262 in [2251;2500], as job id is i=10)"
[1] "seed 38622 for j=13 out of 250 (i.e. j=2263 in [2251;2500], as job id is i=10)"
[1] "seed 29095 for j=14 out of 250 (i.e. j=2264 in [2251;2500], as job id is i=10)"
[1] "seed 58289 for j=15 out of 250 (i.e. j=2265 in [2251;2500], as job id is i=10)"
[1] "seed 17445 for j=16 out of 250 (i.e. j=2266 in [2251;2500], as job id is i=10)"
[1] "seed 64694 for j=17 out of 250 (i.e. j=2267 in [2251;2500], as job id is i=10)"
[1] "seed 80999 for j=18 out of 250 (i.e. j=2268 in [2251;2500], as job id is i=10)"
[1] "seed 49044 for j=19 out of 250 (i.e. j=2269 in [2251;2500], as job id is i=10)"
[1] "seed 99836 for j=20 out of 250 (i.e. j=2270 in [2251;2500], as job id is i=10)"
[1] "seed 99038 for j=21 out of 250 (i.e. j=2271 in [2251;2500], as job id is i=10)"
[1] "seed 35165 for j=22 out of 250 (i.e. j=2272 in [2251;2500], as job id is i=10)"
[1] "seed 6574 for j=23 out of 250 (i.e. j=2273 in [2251;2500], as job id is i=10)"
[1] "seed 98273 for j=24 out of 250 (i.e. j=2274 in [2251;2500], as job id is i=10)"
[1] "seed 85170 for j=25 out of 250 (i.e. j=2275 in [2251;2500], as job id is i=10)"
[1] "seed 61303 for j=26 out of 250 (i.e. j=2276 in [2251;2500], as job id is i=10)"
[1] "seed 86162 for j=27 out of 250 (i.e. j=2277 in [2251;2500], as job id is i=10)"
[1] "seed 31682 for j=28 out of 250 (i.e. j=2278 in [2251;2500], as job id is i=10)"
[1] "seed 11484 for j=29 out of 250 (i.e. j=2279 in [2251;2500], as job id is i=10)"
[1] "seed 24091 for j=30 out of 250 (i.e. j=2280 in [2251;2500], as job id is i=10)"
[1] "seed 85542 for j=31 out of 250 (i.e. j=2281 in [2251;2500], as job id is i=10)"
[1] "seed 75520 for j=32 out of 250 (i.e. j=2282 in [2251;2500], as job id is i=10)"
[1] "seed 11179 for j=33 out of 250 (i.e. j=2283 in [2251;2500], as job id is i=10)"
[1] "seed 28568 for j=34 out of 250 (i.e. j=2284 in [2251;2500], as job id is i=10)"
[1] "seed 42036 for j=35 out of 250 (i.e. j=2285 in [2251;2500], as job id is i=10)"
[1] "seed 23729 for j=36 out of 250 (i.e. j=2286 in [2251;2500], as job id is i=10)"
[1] "seed 29757 for j=37 out of 250 (i.e. j=2287 in [2251;2500], as job id is i=10)"
[1] "seed 7920 for j=38 out of 250 (i.e. j=2288 in [2251;2500], as job id is i=10)"
[1] "seed 17667 for j=39 out of 250 (i.e. j=2289 in [2251;2500], as job id is i=10)"
[1] "seed 64362 for j=40 out of 250 (i.e. j=2290 in [2251;2500], as job id is i=10)"
[1] "seed 74677 for j=41 out of 250 (i.e. j=2291 in [2251;2500], as job id is i=10)"
[1] "seed 58187 for j=42 out of 250 (i.e. j=2292 in [2251;2500], as job id is i=10)"
[1] "seed 91211 for j=43 out of 250 (i.e. j=2293 in [2251;2500], as job id is i=10)"
[1] "seed 12857 for j=44 out of 250 (i.e. j=2294 in [2251;2500], as job id is i=10)"
[1] "seed 92503 for j=45 out of 250 (i.e. j=2295 in [2251;2500], as job id is i=10)"
[1] "seed 95244 for j=46 out of 250 (i.e. j=2296 in [2251;2500], as job id is i=10)"
[1] "seed 42535 for j=47 out of 250 (i.e. j=2297 in [2251;2500], as job id is i=10)"
[1] "seed 14876 for j=48 out of 250 (i.e. j=2298 in [2251;2500], as job id is i=10)"
[1] "seed 93118 for j=49 out of 250 (i.e. j=2299 in [2251;2500], as job id is i=10)"
[1] "seed 72242 for j=50 out of 250 (i.e. j=2300 in [2251;2500], as job id is i=10)"
[1] "seed 36333 for j=51 out of 250 (i.e. j=2301 in [2251;2500], as job id is i=10)"
[1] "seed 10906 for j=52 out of 250 (i.e. j=2302 in [2251;2500], as job id is i=10)"
[1] "seed 83420 for j=53 out of 250 (i.e. j=2303 in [2251;2500], as job id is i=10)"
[1] "seed 29690 for j=54 out of 250 (i.e. j=2304 in [2251;2500], as job id is i=10)"
[1] "seed 14162 for j=55 out of 250 (i.e. j=2305 in [2251;2500], as job id is i=10)"
[1] "seed 90690 for j=56 out of 250 (i.e. j=2306 in [2251;2500], as job id is i=10)"
[1] "seed 42058 for j=57 out of 250 (i.e. j=2307 in [2251;2500], as job id is i=10)"
[1] "seed 77902 for j=58 out of 250 (i.e. j=2308 in [2251;2500], as job id is i=10)"
[1] "seed 97974 for j=59 out of 250 (i.e. j=2309 in [2251;2500], as job id is i=10)"
[1] "seed 85573 for j=60 out of 250 (i.e. j=2310 in [2251;2500], as job id is i=10)"
[1] "seed 79418 for j=61 out of 250 (i.e. j=2311 in [2251;2500], as job id is i=10)"
[1] "seed 88036 for j=62 out of 250 (i.e. j=2312 in [2251;2500], as job id is i=10)"
[1] "seed 50101 for j=63 out of 250 (i.e. j=2313 in [2251;2500], as job id is i=10)"
[1] "seed 36892 for j=64 out of 250 (i.e. j=2314 in [2251;2500], as job id is i=10)"
[1] "seed 30110 for j=65 out of 250 (i.e. j=2315 in [2251;2500], as job id is i=10)"
[1] "seed 94331 for j=66 out of 250 (i.e. j=2316 in [2251;2500], as job id is i=10)"
[1] "seed 53593 for j=67 out of 250 (i.e. j=2317 in [2251;2500], as job id is i=10)"
[1] "seed 9203 for j=68 out of 250 (i.e. j=2318 in [2251;2500], as job id is i=10)"
[1] "seed 28361 for j=69 out of 250 (i.e. j=2319 in [2251;2500], as job id is i=10)"
Error in uniroot(function(x) { : 
  f() values at end points not of opposite sign
Calls: update ... update.delayedGSD -> updateBoundaries -> updateMethod1 -> uniroot
In addition: Warning messages:
1: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

2: In updateBoundaries(object, k = k, type.k = type.k, trace = trace -  :
  Information has decreased between interim and decision. 

Execution halted
